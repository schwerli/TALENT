<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Models &mdash; LAMDA-TALENT  documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../_static/doctools.js"></script>
        <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Methods" href="methods.html" />
    <link rel="prev" title="Deep Learning Models" href="deep_learning.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> LAMDA-TALENT
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Tutorials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../tutorials.html">How to Use TALENT</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials.html#cloning-the-repository">1. Cloning the Repository</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials.html#running-experiments">2. Running Experiments</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials.html#adding-new-methods">3. Adding New Methods</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials.html#configuring-hyperparameters">4. Configuring Hyperparameters</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials.html#troubleshooting">5. Troubleshooting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials.html#conclusion">Conclusion</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Methods</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../methods.html">Methods in TALENT</a></li>
<li class="toctree-l1"><a class="reference internal" href="../methods.html#deep-learning-methods">Deep Learning Methods</a></li>
<li class="toctree-l1"><a class="reference internal" href="../methods.html#classical-methods">Classical Methods</a></li>
<li class="toctree-l1"><a class="reference internal" href="../methods.html#methodology-summary">Methodology Summary</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Dependencies</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../dependencies.html">Dependencies</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dependencies.html#python-libraries">Python Libraries</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dependencies.html#optional-dependencies">Optional Dependencies</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dependencies.html#installation">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dependencies.html#additional-notes">Additional Notes</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Benchmark_Datasets</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../benchmark_datasets.html">Benchmark Datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../benchmark_datasets.html#available-datasets">Available Datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../benchmark_datasets.html#downloading-datasets">Downloading Datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../benchmark_datasets.html#dataset-structure">Dataset Structure</a></li>
<li class="toctree-l1"><a class="reference internal" href="../benchmark_datasets.html#placing-datasets">Placing Datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../benchmark_datasets.html#using-datasets">Using Datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../benchmark_datasets.html#custom-datasets">Custom Datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../benchmark_datasets.html#task-types">Task Types</a></li>
<li class="toctree-l1"><a class="reference internal" href="../benchmark_datasets.html#conclusion">Conclusion</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Experimental_Results</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../experimental_results.html">Experimental Results</a></li>
<li class="toctree-l1"><a class="reference internal" href="../experimental_results.html#evaluation-metrics">Evaluation Metrics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../experimental_results.html#results-summary">Results Summary</a></li>
<li class="toctree-l1"><a class="reference internal" href="../experimental_results.html#conclusion">Conclusion</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Docs</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="core.html">Core Components</a></li>
<li class="toctree-l1"><a class="reference internal" href="classical_methods.html">Classical Methods</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="deep_learning.html">Deep Learning Models</a><ul class="current">
<li class="toctree-l2 current"><a class="current reference internal" href="#">Models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#basic-neural-networks">Basic Neural Networks</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#module-TALENT.model.models.mlp">Multi-Layer Perceptron (MLP)</a></li>
<li class="toctree-l4"><a class="reference internal" href="#module-TALENT.model.models.resnet">Residual Network (ResNet)</a></li>
<li class="toctree-l4"><a class="reference internal" href="#module-TALENT.model.models.snn">Self-Normalizing Network (SNN)</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#transformer-based-models">Transformer-Based Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#module-TALENT.model.models.ftt">Feature Tokenizer Transformer (FT-Transformer)</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#advanced-tabular-models">Advanced Tabular Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#module-TALENT.model.models.tabnet">TabNet</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#tree-based-neural-models">Tree-Based Neural Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#module-TALENT.model.models.grande">GRANDE (Gradient-Boosted Neural Decision Ensembles)</a></li>
<li class="toctree-l4"><a class="reference internal" href="#module-TALENT.model.models.node">Neural Oblivious Decision Ensembles (NODE)</a></li>
<li class="toctree-l4"><a class="reference internal" href="#module-TALENT.model.models.grownet">GrowNet (Gradient Boosting with Neural Networks)</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#distance-based-models">Distance-Based Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#modern-neighborhood-component-analysis-modernnca">Modern Neighborhood Component Analysis (ModernNCA)</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#specialized-architectures">Specialized Architectures</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#module-TALENT.model.models.excelformer">ExcelFormer (Semi-Permeable Attention)</a></li>
<li class="toctree-l4"><a class="reference internal" href="#module-TALENT.model.models.protogate">ProtoGate (Prototype-Based Gating)</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#retrieval-based-models">Retrieval-Based Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#module-TALENT.model.models.tabr">TabR (Tabular Retrieval)</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#foundation-models">Foundation Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#module-TALENT.model.models.tabpfn">TabPFN (Tabular Prior-Fitting Networks)</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#regularization-methods">Regularization Methods</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#tangos-regularization">TANGOS Regularization</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#activation-functions-reference">Activation Functions Reference</a></li>
<li class="toctree-l3"><a class="reference internal" href="#model-usage-examples">Model Usage Examples</a></li>
<li class="toctree-l3"><a class="reference internal" href="#model-selection-guidelines">Model Selection Guidelines</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="methods.html">Methods</a></li>
<li class="toctree-l2"><a class="reference internal" href="methods.html#base-method-class-method-base-py">Base Method Class (method/base.py)</a></li>
<li class="toctree-l2"><a class="reference internal" href="methods.html#method-implementations">Method Implementations</a></li>
<li class="toctree-l2"><a class="reference internal" href="methods.html#method-usage-guidelines">Method Usage Guidelines</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lib.html">Library Components</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Acknowledgements</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../acknowledgements.html">Acknowledgments</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">LAMDA-TALENT</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="deep_learning.html">Deep Learning Models</a> &raquo;</li>
      <li>Models</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/api/models.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="models">
<h1>Models<a class="headerlink" href="#models" title="Permalink to this heading"></a></h1>
<p>Deep learning models for tabular data, implementing various state-of-the-art architectures.</p>
<p>This section contains all the neural network architectures implemented in TALENT, ranging from simple MLPs to advanced transformer-based models specifically designed for tabular data. Each model implements specific forward pass computations, mathematical operations, and architectural innovations.</p>
<section id="basic-neural-networks">
<h2>Basic Neural Networks<a class="headerlink" href="#basic-neural-networks" title="Permalink to this heading"></a></h2>
<section id="module-TALENT.model.models.mlp">
<span id="multi-layer-perceptron-mlp"></span><h3>Multi-Layer Perceptron (MLP)<a class="headerlink" href="#module-TALENT.model.models.mlp" title="Permalink to this heading"></a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="TALENT.model.models.mlp.MLP">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">TALENT.model.models.mlp.</span></span><span class="sig-name descname"><span class="pre">MLP</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.13)"><span class="pre">Any</span></a></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.13)"><span class="pre">Any</span></a></span></em><span class="sig-paren">)</span><a class="headerlink" href="#TALENT.model.models.mlp.MLP" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="TALENT.model.models.mlp.MLP.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x_cat</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#TALENT.model.models.mlp.MLP.forward" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">TALENT.model.models.mlp.</span></span><span class="sig-name descname"><span class="pre">MLP</span></span></dt>
<dd><p>Simple feedforward neural network with multiple fully connected layers and ReLU activations.</p>
<p><strong>Mathematical Formulation:</strong></p>
<p>For input <span class="math notranslate nohighlight">\(x \in \mathbb{R}^{d_{in}}\)</span>, the MLP computes:</p>
<div class="math notranslate nohighlight">
\[\begin{split}h_0 &amp;= x \\
h_i &amp;= \text{ReLU}(\text{Linear}(h_{i-1})) = \text{ReLU}(W_i h_{i-1} + b_i) \\
\text{output} &amp;= W_{\text{head}} h_L + b_{\text{head}}\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(L\)</span> is the number of hidden layers.</p>
<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">d_in</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">d_out</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">d_layers</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Initialize the MLP architecture.</p>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p><strong>d_in</strong> (<em>int</em>) – Input feature dimension</p></li>
<li><p><strong>d_out</strong> (<em>int</em>) – Output dimension (number of classes for classification, 1 for regression)</p></li>
<li><p><strong>d_layers</strong> (<em>List[int]</em>) – Hidden layer dimensions, e.g., [64, 32] for two hidden layers</p></li>
<li><p><strong>dropout</strong> (<em>float</em>) – Dropout probability applied after each hidden layer</p></li>
</ul>
<p><strong>Architecture Construction:</strong></p>
<ol class="arabic simple">
<li><p><strong>Hidden Layers:</strong> Creates <cite>nn.Linear</cite> layers with dimensions specified in <cite>d_layers</cite></p></li>
<li><p><strong>Output Head:</strong> Final linear layer mapping to output dimension</p></li>
<li><p><strong>Dropout Setup:</strong> Configures dropout for regularization during training</p></li>
</ol>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x_cat</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Forward pass through the MLP network.</p>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p><strong>x</strong> (<em>torch.Tensor</em>) – Input numerical features of shape (batch_size, d_in)</p></li>
<li><p><strong>x_cat</strong> (<em>torch.Tensor, optional</em>) – Categorical features (not used in MLP, maintained for interface consistency)</p></li>
</ul>
<p><strong>Returns:</strong></p>
<ul class="simple">
<li><p><strong>torch.Tensor</strong> – Output predictions of shape (batch_size, d_out) or (batch_size,) for regression</p></li>
</ul>
<p><strong>Forward Pass Implementation:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># Linear: x = W @ x + b</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># ReLU: x = max(0, x)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">)</span>

<span class="n">logit</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># Final output layer</span>
<span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">d_out</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
    <span class="n">logit</span> <span class="o">=</span> <span class="n">logit</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># For regression</span>
</pre></div>
</div>
<p><strong>ReLU Activation:</strong></p>
<div class="math notranslate nohighlight">
\[\text{ReLU}(x) = \max(0, x)\]</div>
<p><strong>Dropout Regularization:</strong></p>
<p>During training, randomly sets elements to zero with probability <cite>dropout</cite>:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\text{Dropout}(x) = \begin{cases}
\frac{x}{1-p} &amp; \text{with probability } 1-p \\
0 &amp; \text{with probability } p
\end{cases}\end{split}\]</div>
</dd></dl>

</dd></dl>

</section>
<section id="module-TALENT.model.models.resnet">
<span id="residual-network-resnet"></span><h3>Residual Network (ResNet)<a class="headerlink" href="#module-TALENT.model.models.resnet" title="Permalink to this heading"></a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="TALENT.model.models.resnet.ResNet">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">TALENT.model.models.resnet.</span></span><span class="sig-name descname"><span class="pre">ResNet</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.13)"><span class="pre">Any</span></a></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.13)"><span class="pre">Any</span></a></span></em><span class="sig-paren">)</span><a class="headerlink" href="#TALENT.model.models.resnet.ResNet" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="TALENT.model.models.resnet.ResNet.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x_cat</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#TALENT.model.models.resnet.ResNet.forward" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="TALENT.model.models.resnet.geglu">
<span class="sig-prename descclassname"><span class="pre">TALENT.model.models.resnet.</span></span><span class="sig-name descname"><span class="pre">geglu</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#TALENT.model.models.resnet.geglu" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="TALENT.model.models.resnet.get_activation_fn">
<span class="sig-prename descclassname"><span class="pre">TALENT.model.models.resnet.</span></span><span class="sig-name descname"><span class="pre">get_activation_fn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#TALENT.model.models.resnet.get_activation_fn" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="TALENT.model.models.resnet.get_nonglu_activation_fn">
<span class="sig-prename descclassname"><span class="pre">TALENT.model.models.resnet.</span></span><span class="sig-name descname"><span class="pre">get_nonglu_activation_fn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#TALENT.model.models.resnet.get_nonglu_activation_fn" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="TALENT.model.models.resnet.reglu">
<span class="sig-prename descclassname"><span class="pre">TALENT.model.models.resnet.</span></span><span class="sig-name descname"><span class="pre">reglu</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#TALENT.model.models.resnet.reglu" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py class">
<dt class="sig sig-object py">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">TALENT.model.models.resnet.</span></span><span class="sig-name descname"><span class="pre">ResNet</span></span></dt>
<dd><p>Deep residual network with skip connections for tabular data, preventing gradient vanishing in deep architectures.</p>
<p><strong>Mathematical Formulation:</strong></p>
<p>ResNet uses residual blocks with skip connections:</p>
<div class="math notranslate nohighlight">
\[h_{i+1} = h_i + F(h_i, W_i)\]</div>
<p>where <span class="math notranslate nohighlight">\(F(h_i, W_i)\)</span> is the residual function.</p>
<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">d_in</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">d</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">d_hidden_factor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_layers</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">normalization</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_dropout</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">residual_dropout</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">d_out</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Initialize the ResNet architecture with configurable components.</p>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p><strong>d_in</strong> (<em>int</em>) – Input feature dimension</p></li>
<li><p><strong>d</strong> (<em>int</em>) – Hidden dimension for residual blocks</p></li>
<li><p><strong>d_hidden_factor</strong> (<em>float</em>) – Factor to scale hidden layer width within blocks</p></li>
<li><p><strong>n_layers</strong> (<em>int</em>) – Number of residual blocks</p></li>
<li><p><strong>activation</strong> (<em>str</em>) – Activation function (‘relu’, ‘gelu’, ‘reglu’, ‘geglu’)</p></li>
<li><p><strong>normalization</strong> (<em>str</em>) – Normalization type (‘batchnorm’, ‘layernorm’)</p></li>
<li><p><strong>hidden_dropout</strong> (<em>float</em>) – Dropout probability within residual blocks</p></li>
<li><p><strong>residual_dropout</strong> (<em>float</em>) – Dropout probability for residual connections</p></li>
<li><p><strong>d_out</strong> (<em>int</em>) – Output dimension</p></li>
</ul>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x_cat</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Forward pass through the ResNet architecture.</p>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p><strong>x</strong> (<em>torch.Tensor</em>) – Input numerical features</p></li>
<li><p><strong>x_cat</strong> (<em>torch.Tensor, optional</em>) – Categorical features (not used)</p></li>
</ul>
<p><strong>Returns:</strong></p>
<ul class="simple">
<li><p><strong>torch.Tensor</strong> – Output predictions</p></li>
</ul>
<p><strong>Residual Block Mathematical Implementation:</strong></p>
<p>For each residual block, the computation follows:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\text{residual} &amp;= \text{Norm}(h_i) \\
\text{residual} &amp;= \text{Linear}(\text{residual}) \\
\text{residual} &amp;= \text{Activation}(\text{residual}) \\
\text{residual} &amp;= \text{Dropout}(\text{residual}) \\
\text{residual} &amp;= \text{Linear}(\text{residual}) \\
\text{residual} &amp;= \text{Dropout}(\text{residual}) \\
h_{i+1} &amp;= h_i + \text{residual}\end{split}\]</div>
<p><strong>Activation Functions:</strong></p>
<ul class="simple">
<li><p><strong>ReLU:</strong> <span class="math notranslate nohighlight">\(\text{ReLU}(x) = \max(0, x)\)</span></p></li>
<li><p><strong>GELU:</strong> <span class="math notranslate nohighlight">\(\text{GELU}(x) = x \cdot \Phi(x)\)</span></p></li>
<li><p><strong>ReGLU:</strong> <span class="math notranslate nohighlight">\(\text{ReGLU}(x) = a \cdot \text{ReLU}(b)\)</span> where <span class="math notranslate nohighlight">\(a, b = \text{split}(x)\)</span></p></li>
<li><p><strong>GeGLU:</strong> <span class="math notranslate nohighlight">\(\text{GeGLU}(x) = a \cdot \text{GELU}(b)\)</span> where <span class="math notranslate nohighlight">\(a, b = \text{split}(x)\)</span></p></li>
</ul>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">reglu</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>ReGLU activation function for gated linear units.</p>
<p><strong>Mathematical Definition:</strong></p>
<div class="math notranslate nohighlight">
\[\text{ReGLU}(x) = a \cdot \text{ReLU}(b)\]</div>
<p>where <span class="math notranslate nohighlight">\(a\)</span> and <span class="math notranslate nohighlight">\(b\)</span> are obtained by splitting <span class="math notranslate nohighlight">\(x\)</span> along the last dimension.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">geglu</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>GeGLU activation function combining gating with GELU.</p>
<p><strong>Mathematical Definition:</strong></p>
<div class="math notranslate nohighlight">
\[\text{GeGLU}(x) = a \cdot \text{GELU}(b)\]</div>
<p>where <span class="math notranslate nohighlight">\(a\)</span> and <span class="math notranslate nohighlight">\(b\)</span> are obtained by splitting <span class="math notranslate nohighlight">\(x\)</span> along the last dimension.</p>
</dd></dl>

</dd></dl>

</section>
<section id="module-TALENT.model.models.snn">
<span id="self-normalizing-network-snn"></span><h3>Self-Normalizing Network (SNN)<a class="headerlink" href="#module-TALENT.model.models.snn" title="Permalink to this heading"></a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="TALENT.model.models.snn.SNN">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">TALENT.model.models.snn.</span></span><span class="sig-name descname"><span class="pre">SNN</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.13)"><span class="pre">Any</span></a></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.13)"><span class="pre">Any</span></a></span></em><span class="sig-paren">)</span><a class="headerlink" href="#TALENT.model.models.snn.SNN" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="TALENT.model.models.snn.SNN.calculate_output">
<span class="sig-name descname"><span class="pre">calculate_output</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#TALENT.model.models.snn.SNN.calculate_output" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="TALENT.model.models.snn.SNN.d_embedding">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">d_embedding</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a></em><a class="headerlink" href="#TALENT.model.models.snn.SNN.d_embedding" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="TALENT.model.models.snn.SNN.encode">
<span class="sig-name descname"><span class="pre">encode</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x_num</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x_cat</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#TALENT.model.models.snn.SNN.encode" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="TALENT.model.models.snn.SNN.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x_num</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x_cat</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#TALENT.model.models.snn.SNN.forward" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">TALENT.model.models.snn.</span></span><span class="sig-name descname"><span class="pre">SNN</span></span></dt>
<dd><p>Lightweight neural network with self-normalizing properties using SELU activation.</p>
<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">d_in</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">d_out</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">d_layers</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Initialize SNN with SELU activations for self-normalization.</p>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p><strong>d_in</strong> (<em>int</em>) – Input dimension</p></li>
<li><p><strong>d_out</strong> (<em>int</em>) – Output dimension</p></li>
<li><p><strong>d_layers</strong> (<em>List[int]</em>) – Hidden layer dimensions</p></li>
<li><p><strong>dropout</strong> (<em>float</em>) – Dropout probability</p></li>
</ul>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x_cat</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Forward pass with SELU activation for self-normalization.</p>
<p><strong>SELU Activation Mathematical Definition:</strong></p>
<div class="math notranslate nohighlight">
\[\begin{split}\text{SELU}(x) = \lambda \begin{cases}
x &amp; \text{if } x &gt; 0 \\
\alpha(e^x - 1) &amp; \text{if } x \leq 0
\end{cases}\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(\lambda \approx 1.0507\)</span> and <span class="math notranslate nohighlight">\(\alpha \approx 1.6733\)</span>.</p>
<p><strong>Self-Normalization Property:</strong></p>
<p>SELU ensures that for normalized inputs, activations maintain:
- Mean converges to 0
- Variance converges to 1
- Enables training of very deep networks without explicit normalization</p>
</dd></dl>

</dd></dl>

</section>
</section>
<section id="transformer-based-models">
<h2>Transformer-Based Models<a class="headerlink" href="#transformer-based-models" title="Permalink to this heading"></a></h2>
<section id="module-TALENT.model.models.ftt">
<span id="feature-tokenizer-transformer-ft-transformer"></span><h3>Feature Tokenizer Transformer (FT-Transformer)<a class="headerlink" href="#module-TALENT.model.models.ftt" title="Permalink to this heading"></a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="TALENT.model.models.ftt.MultiheadAttention">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">TALENT.model.models.ftt.</span></span><span class="sig-name descname"><span class="pre">MultiheadAttention</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.13)"><span class="pre">Any</span></a></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.13)"><span class="pre">Any</span></a></span></em><span class="sig-paren">)</span><a class="headerlink" href="#TALENT.model.models.ftt.MultiheadAttention" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="TALENT.model.models.ftt.MultiheadAttention.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x_q</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x_kv</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">key_compression</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.13)"><span class="pre">Optional</span></a><span class="p"><span class="pre">[</span></span><span class="pre">torch.nn.Linear</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">value_compression</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.13)"><span class="pre">Optional</span></a><span class="p"><span class="pre">[</span></span><span class="pre">torch.nn.Linear</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#TALENT.model.models.ftt.MultiheadAttention.forward" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="TALENT.model.models.ftt.Tokenizer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">TALENT.model.models.ftt.</span></span><span class="sig-name descname"><span class="pre">Tokenizer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.13)"><span class="pre">Any</span></a></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.13)"><span class="pre">Any</span></a></span></em><span class="sig-paren">)</span><a class="headerlink" href="#TALENT.model.models.ftt.Tokenizer" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<dl class="py attribute">
<dt class="sig sig-object py" id="TALENT.model.models.ftt.Tokenizer.category_offsets">
<span class="sig-name descname"><span class="pre">category_offsets</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.13)"><span class="pre">Optional</span></a><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#TALENT.model.models.ftt.Tokenizer.category_offsets" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="TALENT.model.models.ftt.Tokenizer.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x_num</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x_cat</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.13)"><span class="pre">Optional</span></a><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#TALENT.model.models.ftt.Tokenizer.forward" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="TALENT.model.models.ftt.Tokenizer.n_tokens">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">n_tokens</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a></em><a class="headerlink" href="#TALENT.model.models.ftt.Tokenizer.n_tokens" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="TALENT.model.models.ftt.Transformer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">TALENT.model.models.ftt.</span></span><span class="sig-name descname"><span class="pre">Transformer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.13)"><span class="pre">Any</span></a></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.13)"><span class="pre">Any</span></a></span></em><span class="sig-paren">)</span><a class="headerlink" href="#TALENT.model.models.ftt.Transformer" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Transformer.</p>
<p>References:
- <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.Transformer.html">https://pytorch.org/docs/stable/generated/torch.nn.Transformer.html</a>
- <a class="reference external" href="https://github.com/facebookresearch/pytext/tree/master/pytext/models/representations/transformer">https://github.com/facebookresearch/pytext/tree/master/pytext/models/representations/transformer</a>
- <a class="reference external" href="https://github.com/pytorch/fairseq/blob/1bba712622b8ae4efb3eb793a8a40da386fe11d0/examples/linformer/linformer_src/modules/multihead_linear_attention.py#L19">https://github.com/pytorch/fairseq/blob/1bba712622b8ae4efb3eb793a8a40da386fe11d0/examples/linformer/linformer_src/modules/multihead_linear_attention.py#L19</a></p>
<dl class="py method">
<dt class="sig sig-object py" id="TALENT.model.models.ftt.Transformer.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x_num</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x_cat</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.13)"><span class="pre">Optional</span></a><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#TALENT.model.models.ftt.Transformer.forward" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="TALENT.model.models.ftt.geglu">
<span class="sig-prename descclassname"><span class="pre">TALENT.model.models.ftt.</span></span><span class="sig-name descname"><span class="pre">geglu</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#TALENT.model.models.ftt.geglu" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="TALENT.model.models.ftt.get_activation_fn">
<span class="sig-prename descclassname"><span class="pre">TALENT.model.models.ftt.</span></span><span class="sig-name descname"><span class="pre">get_activation_fn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#TALENT.model.models.ftt.get_activation_fn" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="TALENT.model.models.ftt.get_nonglu_activation_fn">
<span class="sig-prename descclassname"><span class="pre">TALENT.model.models.ftt.</span></span><span class="sig-name descname"><span class="pre">get_nonglu_activation_fn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#TALENT.model.models.ftt.get_nonglu_activation_fn" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="TALENT.model.models.ftt.reglu">
<span class="sig-prename descclassname"><span class="pre">TALENT.model.models.ftt.</span></span><span class="sig-name descname"><span class="pre">reglu</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#TALENT.model.models.ftt.reglu" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py class">
<dt class="sig sig-object py">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">TALENT.model.models.ftt.</span></span><span class="sig-name descname"><span class="pre">Transformer</span></span></dt>
<dd><p>Advanced transformer architecture specifically designed for tabular data with feature tokenization.</p>
<p><strong>Mathematical Formulation:</strong></p>
<p><strong>Feature Tokenization:</strong></p>
<p>For numerical features: <span class="math notranslate nohighlight">\(t_i^{\text{num}} = W_{\text{num}} x_i + b_{\text{num}}\)</span></p>
<p>For categorical features: <span class="math notranslate nohighlight">\(t_i^{\text{cat}} = \text{Embedding}(x_i^{\text{cat}})\)</span></p>
<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">d_numerical</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">categories</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">d_token</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_layers</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_heads</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">d_ffn_factor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">attention_dropout</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ffn_dropout</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">residual_dropout</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prenormalization</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">d_out</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Initialize the FT-Transformer architecture.</p>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p><strong>d_numerical</strong> (<em>int</em>) – Number of numerical features</p></li>
<li><p><strong>categories</strong> (<em>List[int], optional</em>) – Cardinalities for categorical features</p></li>
<li><p><strong>d_token</strong> (<em>int</em>) – Token embedding dimension</p></li>
<li><p><strong>n_layers</strong> (<em>int</em>) – Number of transformer layers</p></li>
<li><p><strong>n_heads</strong> (<em>int</em>) – Number of attention heads</p></li>
<li><p><strong>d_ffn_factor</strong> (<em>float</em>) – Factor for feed-forward network dimension</p></li>
<li><p><strong>attention_dropout</strong> (<em>float</em>) – Dropout for attention weights</p></li>
<li><p><strong>ffn_dropout</strong> (<em>float</em>) – Dropout for feed-forward network</p></li>
<li><p><strong>residual_dropout</strong> (<em>float</em>) – Dropout for residual connections</p></li>
<li><p><strong>activation</strong> (<em>str</em>) – Activation function for FFN</p></li>
<li><p><strong>prenormalization</strong> (<em>bool</em>) – Whether to use pre-normalization</p></li>
<li><p><strong>d_out</strong> (<em>int</em>) – Output dimension</p></li>
</ul>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x_num</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x_cat</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Forward pass through the transformer.</p>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p><strong>x_num</strong> (<em>torch.Tensor, optional</em>) – Numerical features of shape (batch_size, d_numerical)</p></li>
<li><p><strong>x_cat</strong> (<em>torch.Tensor, optional</em>) – Categorical features of shape (batch_size, n_categorical)</p></li>
</ul>
<p><strong>Returns:</strong></p>
<ul class="simple">
<li><p><strong>torch.Tensor</strong> – Output predictions</p></li>
</ul>
<p><strong>Transformer Processing Pipeline:</strong></p>
<ol class="arabic simple">
<li><p><strong>Tokenization:</strong> Convert features to tokens using <cite>Tokenizer</cite></p></li>
<li><p><strong>CLS Token Addition:</strong> Prepend classification token</p></li>
<li><p><strong>Transformer Layers:</strong> Apply multi-head attention and feed-forward networks</p></li>
<li><p><strong>Output Generation:</strong> Use CLS token representation for final prediction</p></li>
</ol>
<p><strong>Transformer Layer Mathematical Implementation:</strong></p>
<p>For each transformer layer:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\text{attn_out} &amp;= \text{MultiHeadAttention}(x, x, x) \\
x &amp;= \text{LayerNorm}(x + \text{attn_out}) \\
\text{ffn_out} &amp;= \text{FFN}(x) \\
x &amp;= \text{LayerNorm}(x + \text{ffn_out})\end{split}\]</div>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">TALENT.model.models.ftt.</span></span><span class="sig-name descname"><span class="pre">Tokenizer</span></span></dt>
<dd><p>Converts numerical and categorical features into token embeddings for transformer processing.</p>
<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">d_numerical</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">categories</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">d_token</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bias</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Initialize the feature tokenizer.</p>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p><strong>d_numerical</strong> (<em>int</em>) – Number of numerical features</p></li>
<li><p><strong>categories</strong> (<em>List[int], optional</em>) – Cardinalities of categorical features</p></li>
<li><p><strong>d_token</strong> (<em>int</em>) – Token embedding dimension</p></li>
<li><p><strong>bias</strong> (<em>bool</em>) – Whether to use bias in tokenization</p></li>
</ul>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x_num</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x_cat</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Convert features to token embeddings.</p>
<p><strong>Tokenization Process:</strong></p>
<p><strong>Numerical Features:</strong></p>
<div class="math notranslate nohighlight">
\[\text{tokens}_{\text{num}} = x_{\text{num}} W_{\text{num}} + b_{\text{num}}\]</div>
<p><strong>Categorical Features:</strong></p>
<div class="math notranslate nohighlight">
\[\text{tokens}_{\text{cat}} = \text{Embedding}(x_{\text{cat}} + \text{offsets})\]</div>
<p><strong>CLS Token:</strong></p>
<div class="math notranslate nohighlight">
\[\text{tokens}_{\text{cls}} = W_{\text{cls}}\]</div>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">n_tokens</span></span></dt>
<dd><p>Total number of tokens (numerical + categorical + CLS).</p>
<p><strong>Returns:</strong></p>
<ul class="simple">
<li><p><strong>int</strong> – Total token count</p></li>
</ul>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">TALENT.model.models.ftt.</span></span><span class="sig-name descname"><span class="pre">MultiheadAttention</span></span></dt>
<dd><p>Multi-head attention mechanism optimized for tabular data.</p>
<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">d</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_heads</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bias</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Initialize multi-head attention.</p>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p><strong>d</strong> (<em>int</em>) – Input dimension</p></li>
<li><p><strong>n_heads</strong> (<em>int</em>) – Number of attention heads</p></li>
<li><p><strong>dropout</strong> (<em>float</em>) – Attention dropout probability</p></li>
<li><p><strong>bias</strong> (<em>bool</em>) – Whether to use bias in projections</p></li>
</ul>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x_q</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x_kv</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">key_compression</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">value_compression</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Compute multi-head attention.</p>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p><strong>x_q</strong> (<em>torch.Tensor</em>) – Query input</p></li>
<li><p><strong>x_kv</strong> (<em>torch.Tensor</em>) – Key and value input</p></li>
<li><p><strong>key_compression</strong> (<em>nn.Linear, optional</em>) – Key compression layer</p></li>
<li><p><strong>value_compression</strong> (<em>nn.Linear, optional</em>) – Value compression layer</p></li>
</ul>
<p><strong>Returns:</strong></p>
<ul class="simple">
<li><p><strong>torch.Tensor</strong> – Attention output</p></li>
</ul>
<p><strong>Multi-Head Attention Mathematical Implementation:</strong></p>
<ol class="arabic">
<li><p><strong>Linear Projections:</strong></p>
<div class="math notranslate nohighlight">
\[Q = x_q W^Q, \quad K = x_{kv} W^K, \quad V = x_{kv} W^V\]</div>
</li>
<li><p><strong>Scaled Dot-Product Attention:</strong></p>
<div class="math notranslate nohighlight">
\[\text{attention} = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)\]</div>
</li>
<li><p><strong>Output Computation:</strong></p>
<div class="math notranslate nohighlight">
\[\text{output} = \text{attention} \cdot V\]</div>
</li>
<li><p><strong>Multi-Head Combination:</strong></p>
<div class="math notranslate nohighlight">
\[\text{MultiHead}(Q, K, V) = \text{Concat}(\text{head}_1, \ldots, \text{head}_h)W^O\]</div>
</li>
</ol>
</dd></dl>

</dd></dl>

</section>
</section>
<section id="advanced-tabular-models">
<h2>Advanced Tabular Models<a class="headerlink" href="#advanced-tabular-models" title="Permalink to this heading"></a></h2>
<section id="module-TALENT.model.models.tabnet">
<span id="tabnet"></span><h3>TabNet<a class="headerlink" href="#module-TALENT.model.models.tabnet" title="Permalink to this heading"></a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="TALENT.model.models.tabnet.TabNetClassifier">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">TALENT.model.models.tabnet.</span></span><span class="sig-name descname"><span class="pre">TabNetClassifier</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.13)"><span class="pre">Any</span></a></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.13)"><span class="pre">Any</span></a></span></em><span class="sig-paren">)</span><a class="headerlink" href="#TALENT.model.models.tabnet.TabNetClassifier" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">TabModel</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="TALENT.model.models.tabnet.TabNetClassifier.compute_loss">
<span class="sig-name descname"><span class="pre">compute_loss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y_pred</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_true</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#TALENT.model.models.tabnet.TabNetClassifier.compute_loss" title="Permalink to this definition"></a></dt>
<dd><p>Compute the loss.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>y_score</strong> (a :tensor: <cite>torch.Tensor</cite>) – Score matrix</p></li>
<li><p><strong>y_true</strong> (a :tensor: <cite>torch.Tensor</cite>) – Target matrix</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Loss value</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)">float</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="TALENT.model.models.tabnet.TabNetClassifier.predict_func">
<span class="sig-name descname"><span class="pre">predict_func</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">outputs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#TALENT.model.models.tabnet.TabNetClassifier.predict_func" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="TALENT.model.models.tabnet.TabNetClassifier.predict_proba">
<span class="sig-name descname"><span class="pre">predict_proba</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#TALENT.model.models.tabnet.TabNetClassifier.predict_proba" title="Permalink to this definition"></a></dt>
<dd><p>Make predictions for classification on a batch (valid)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> (a :tensor: <cite>torch.Tensor</cite> or matrix: <cite>scipy.sparse.csr_matrix</cite>) – Input data</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>res</strong></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>np.ndarray</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="TALENT.model.models.tabnet.TabNetClassifier.prepare_target">
<span class="sig-name descname"><span class="pre">prepare_target</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#TALENT.model.models.tabnet.TabNetClassifier.prepare_target" title="Permalink to this definition"></a></dt>
<dd><p>Prepare target before training.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>y</strong> (a :tensor: <cite>torch.Tensor</cite>) – Target matrix.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Converted target matrix.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><cite>torch.Tensor</cite></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="TALENT.model.models.tabnet.TabNetClassifier.stack_batches">
<span class="sig-name descname"><span class="pre">stack_batches</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">list_y_true</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">list_y_score</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#TALENT.model.models.tabnet.TabNetClassifier.stack_batches" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="TALENT.model.models.tabnet.TabNetClassifier.update_fit_params">
<span class="sig-name descname"><span class="pre">update_fit_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X_train</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_train</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_set</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weights</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#TALENT.model.models.tabnet.TabNetClassifier.update_fit_params" title="Permalink to this definition"></a></dt>
<dd><p>Set attributes relative to fit function.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X_train</strong> (<em>np.ndarray</em>) – Train set</p></li>
<li><p><strong>y_train</strong> (<em>np.array</em>) – Train targets</p></li>
<li><p><strong>eval_set</strong> (<em>list of tuple</em>) – List of eval tuple set (X, y).</p></li>
<li><p><strong>weights</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em> or </em><em>dictionnary</em>) – 0 for no balancing
1 for automated balancing</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="TALENT.model.models.tabnet.TabNetClassifier.weight_updater">
<span class="sig-name descname"><span class="pre">weight_updater</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">weights</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#TALENT.model.models.tabnet.TabNetClassifier.weight_updater" title="Permalink to this definition"></a></dt>
<dd><p>Updates weights dictionary according to target_mapper.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>weights</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.13)"><em>dict</em></a>) – Given weights for balancing training.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Same bool if weights are bool, updated dict otherwise.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)">bool</a> or <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.13)">dict</a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="TALENT.model.models.tabnet.TabNetRegressor">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">TALENT.model.models.tabnet.</span></span><span class="sig-name descname"><span class="pre">TabNetRegressor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.13)"><span class="pre">Any</span></a></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.13)"><span class="pre">Any</span></a></span></em><span class="sig-paren">)</span><a class="headerlink" href="#TALENT.model.models.tabnet.TabNetRegressor" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">TabModel</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="TALENT.model.models.tabnet.TabNetRegressor.compute_loss">
<span class="sig-name descname"><span class="pre">compute_loss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y_pred</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_true</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#TALENT.model.models.tabnet.TabNetRegressor.compute_loss" title="Permalink to this definition"></a></dt>
<dd><p>Compute the loss.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>y_score</strong> (a :tensor: <cite>torch.Tensor</cite>) – Score matrix</p></li>
<li><p><strong>y_true</strong> (a :tensor: <cite>torch.Tensor</cite>) – Target matrix</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Loss value</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)">float</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="TALENT.model.models.tabnet.TabNetRegressor.predict_func">
<span class="sig-name descname"><span class="pre">predict_func</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">outputs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#TALENT.model.models.tabnet.TabNetRegressor.predict_func" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="TALENT.model.models.tabnet.TabNetRegressor.prepare_target">
<span class="sig-name descname"><span class="pre">prepare_target</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#TALENT.model.models.tabnet.TabNetRegressor.prepare_target" title="Permalink to this definition"></a></dt>
<dd><p>Prepare target before training.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>y</strong> (a :tensor: <cite>torch.Tensor</cite>) – Target matrix.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Converted target matrix.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><cite>torch.Tensor</cite></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="TALENT.model.models.tabnet.TabNetRegressor.stack_batches">
<span class="sig-name descname"><span class="pre">stack_batches</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">list_y_true</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">list_y_score</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#TALENT.model.models.tabnet.TabNetRegressor.stack_batches" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="TALENT.model.models.tabnet.TabNetRegressor.update_fit_params">
<span class="sig-name descname"><span class="pre">update_fit_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X_train</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_train</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_set</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weights</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#TALENT.model.models.tabnet.TabNetRegressor.update_fit_params" title="Permalink to this definition"></a></dt>
<dd><p>Set attributes relative to fit function.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X_train</strong> (<em>np.ndarray</em>) – Train set</p></li>
<li><p><strong>y_train</strong> (<em>np.array</em>) – Train targets</p></li>
<li><p><strong>eval_set</strong> (<em>list of tuple</em>) – List of eval tuple set (X, y).</p></li>
<li><p><strong>weights</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em> or </em><em>dictionnary</em>) – 0 for no balancing
1 for automated balancing</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">TALENT.model.models.tabnet.</span></span><span class="sig-name descname"><span class="pre">TabNetClassifier</span></span></dt>
<dd><p>Interpretable deep learning model with sequential attention mechanism for classification.</p>
<p><strong>Mathematical Formulation:</strong></p>
<p>TabNet uses sequential feature selection through sparsemax attention:</p>
<p><strong>Feature Selection at Step i:</strong></p>
<div class="math notranslate nohighlight">
\[M^{[i]} = \text{sparsemax}(\text{AttentionTransformer}(f^{[i-1]}))\]</div>
<p><strong>Feature Processing:</strong></p>
<div class="math notranslate nohighlight">
\[f^{[i]} = \gamma \odot M^{[i]} \odot h + (1-\gamma) \odot f^{[i-1]}\]</div>
<p>where <span class="math notranslate nohighlight">\(\gamma\)</span> is the relaxation parameter.</p>
<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n_steps</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gamma</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_independent</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_shared</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">momentum</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer_params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scheduler_params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mask_type</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lambda_sparse</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Initialize TabNet classifier.</p>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p><strong>n_steps</strong> (<em>int</em>) – Number of decision steps</p></li>
<li><p><strong>gamma</strong> (<em>float</em>) – Relaxation parameter for feature selection</p></li>
<li><p><strong>n_independent</strong> (<em>int</em>) – Number of independent GLU layers per step</p></li>
<li><p><strong>n_shared</strong> (<em>int</em>) – Number of shared GLU layers</p></li>
<li><p><strong>momentum</strong> (<em>float</em>) – Momentum for batch normalization</p></li>
<li><p><strong>optimizer_params</strong> (<em>dict</em>) – Optimizer configuration</p></li>
<li><p><strong>scheduler_params</strong> (<em>dict</em>) – Learning rate scheduler parameters</p></li>
<li><p><strong>mask_type</strong> (<em>str</em>) – Type of attention mask (‘sparsemax’ or ‘entmax’)</p></li>
<li><p><strong>lambda_sparse</strong> (<em>float</em>) – Sparsity regularization coefficient</p></li>
<li><p><strong>seed</strong> (<em>int</em>) – Random seed</p></li>
</ul>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X_train</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_train</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_set</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_metric</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_epochs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">patience</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">virtual_batch_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_workers</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">drop_last</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Train the TabNet model.</p>
<p><strong>Training Process:</strong></p>
<ol class="arabic simple">
<li><p><strong>Data Preprocessing:</strong> Handle categorical encoding and normalization</p></li>
<li><p><strong>Sequential Training:</strong> Train each decision step sequentially</p></li>
<li><p><strong>Attention Regularization:</strong> Apply sparsity constraints on attention masks</p></li>
<li><p><strong>Early Stopping:</strong> Monitor validation metrics for convergence</p></li>
</ol>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">predict_proba</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Make probability predictions for classification.</p>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p><strong>X</strong> (<em>torch.Tensor or scipy.sparse matrix</em>) – Input features</p></li>
</ul>
<p><strong>Returns:</strong></p>
<ul class="simple">
<li><p><strong>np.ndarray</strong> – Class probabilities of shape (n_samples, n_classes)</p></li>
</ul>
<p><strong>Prediction Process:</strong></p>
<ol class="arabic simple">
<li><p><strong>Forward Pass:</strong> Process through all decision steps</p></li>
<li><p><strong>Attention Aggregation:</strong> Combine attention from all steps</p></li>
<li><p><strong>Softmax Application:</strong> Convert logits to probabilities</p></li>
</ol>
<div class="math notranslate nohighlight">
\[P(y=k|x) = \frac{\exp(o_k)}{\sum_{j=1}^K \exp(o_j)}\]</div>
<p>where <span class="math notranslate nohighlight">\(o_k\)</span> is the raw output for class <span class="math notranslate nohighlight">\(k\)</span>.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">explain</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">normalize</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Generate feature importance explanations using attention masks.</p>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p><strong>X</strong> (<em>torch.Tensor</em>) – Input features</p></li>
<li><p><strong>normalize</strong> (<em>bool</em>) – Whether to normalize importance scores</p></li>
</ul>
<p><strong>Returns:</strong></p>
<ul class="simple">
<li><p><strong>np.ndarray</strong> – Feature importance matrix</p></li>
</ul>
<p><strong>Explanation Generation:</strong></p>
<p>Attention masks from each decision step provide interpretable feature importance:</p>
<div class="math notranslate nohighlight">
\[\text{importance}_{ij} = \frac{M^{[i]}_j}{\sum_{k=1}^{n_features} M^{[i]}_k}\]</div>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">TALENT.model.models.tabnet.</span></span><span class="sig-name descname"><span class="pre">TabNetRegressor</span></span></dt>
<dd><p>TabNet for regression tasks with mean squared error optimization.</p>
<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">compute_loss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y_pred</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_true</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Compute mean squared error loss for regression.</p>
<p><strong>MSE Loss Mathematical Definition:</strong></p>
<div class="math notranslate nohighlight">
\[\mathcal{L}_{\text{MSE}} = \frac{1}{n} \sum_{i=1}^n (y_i - \hat{y}_i)^2\]</div>
</dd></dl>

</dd></dl>

</section>
</section>
<section id="tree-based-neural-models">
<h2>Tree-Based Neural Models<a class="headerlink" href="#tree-based-neural-models" title="Permalink to this heading"></a></h2>
<section id="module-TALENT.model.models.grande">
<span id="grande-gradient-boosted-neural-decision-ensembles"></span><h3>GRANDE (Gradient-Boosted Neural Decision Ensembles)<a class="headerlink" href="#module-TALENT.model.models.grande" title="Permalink to this heading"></a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="TALENT.model.models.grande.GRANDE">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">TALENT.model.models.grande.</span></span><span class="sig-name descname"><span class="pre">GRANDE</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.13)"><span class="pre">Any</span></a></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.13)"><span class="pre">Any</span></a></span></em><span class="sig-paren">)</span><a class="headerlink" href="#TALENT.model.models.grande.GRANDE" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="TALENT.model.models.grande.GRANDE.apply_preprocessing">
<span class="sig-name descname"><span class="pre">apply_preprocessing</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#TALENT.model.models.grande.GRANDE.apply_preprocessing" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="TALENT.model.models.grande.GRANDE.build_model">
<span class="sig-name descname"><span class="pre">build_model</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#TALENT.model.models.grande.GRANDE.build_model" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="TALENT.model.models.grande.GRANDE.entmax15">
<span class="sig-name descname"><span class="pre">entmax15</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-</span> <span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#TALENT.model.models.grande.GRANDE.entmax15" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="TALENT.model.models.grande.GRANDE.entmax_threshold_and_support">
<span class="sig-name descname"><span class="pre">entmax_threshold_and_support</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-</span> <span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#TALENT.model.models.grande.GRANDE.entmax_threshold_and_support" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="TALENT.model.models.grande.GRANDE.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#TALENT.model.models.grande.GRANDE.forward" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="TALENT.model.models.grande.GRANDE.preprocess_data">
<span class="sig-name descname"><span class="pre">preprocess_data</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X_train</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_train</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_val</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_val</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#TALENT.model.models.grande.GRANDE.preprocess_data" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="TALENT.model.models.grande.GRANDE.set_params">
<span class="sig-name descname"><span class="pre">set_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#TALENT.model.models.grande.GRANDE.set_params" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">TALENT.model.models.grande.</span></span><span class="sig-name descname"><span class="pre">GRANDE</span></span></dt>
<dd><p>Tree-mimic neural network using gradient descent for decision tree simulation.</p>
<p><strong>Mathematical Formulation:</strong></p>
<p>GRANDE simulates decision trees using neural operations with entmax for sparse selection.</p>
<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">task_type</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">depth</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_estimators</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Initialize GRANDE model.</p>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p><strong>batch_size</strong> (<em>int</em>) – Training batch size</p></li>
<li><p><strong>task_type</strong> (<em>str</em>) – ‘classification’ or ‘regression’</p></li>
<li><p><strong>depth</strong> (<em>int</em>) – Maximum tree depth</p></li>
<li><p><strong>n_estimators</strong> (<em>int</em>) – Number of tree estimators</p></li>
<li><p><strong>dropout</strong> (<em>float</em>) – Dropout probability</p></li>
</ul>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Forward pass through the GRANDE ensemble.</p>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p><strong>inputs</strong> (<em>torch.Tensor</em>) – Input features</p></li>
</ul>
<p><strong>Returns:</strong></p>
<ul class="simple">
<li><p><strong>torch.Tensor</strong> – Ensemble predictions</p></li>
</ul>
<p><strong>Tree Simulation Mathematical Implementation:</strong></p>
<ol class="arabic">
<li><p><strong>Split Decision Computation:</strong></p>
<div class="math notranslate nohighlight">
\[\text{node_result} = \frac{\text{softsign}(s_1 - s_2) + 1}{2}\]</div>
<p>where <span class="math notranslate nohighlight">\(s_1\)</span> are learned split thresholds and <span class="math notranslate nohighlight">\(s_2\)</span> are feature values.</p>
</li>
<li><p><strong>Path Probability Calculation:</strong></p>
<div class="math notranslate nohighlight">
\[p = \prod_{j} ((1-\text{path_id}_j) \cdot \text{node_result}_j + \text{path_id}_j \cdot (1-\text{node_result}_j))\]</div>
</li>
<li><p><strong>Ensemble Output for Regression:</strong></p>
<div class="math notranslate nohighlight">
\[\text{output} = \sum_{e,l} w_e \cdot p_{e,l} \cdot v_{e,l}\]</div>
<p>where <span class="math notranslate nohighlight">\(w_e\)</span> are estimator weights, <span class="math notranslate nohighlight">\(p_{e,l}\)</span> are leaf probabilities, and <span class="math notranslate nohighlight">\(v_{e,l}\)</span> are leaf values.</p>
</li>
<li><p><strong>Ensemble Output for Classification:</strong></p>
<div class="math notranslate nohighlight">
\[\text{output} = \sum_{e,l} w_e \cdot p_{e,l} \cdot \text{softmax}(v_{e,l})\]</div>
</li>
</ol>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">get_representation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Extract intermediate tree representations for analysis.</p>
<p><strong>Returns:</strong></p>
<ul class="simple">
<li><p><strong>torch.Tensor</strong> – Tree path representations</p></li>
</ul>
</dd></dl>

</dd></dl>

</section>
<section id="module-TALENT.model.models.node">
<span id="neural-oblivious-decision-ensembles-node"></span><h3>Neural Oblivious Decision Ensembles (NODE)<a class="headerlink" href="#module-TALENT.model.models.node" title="Permalink to this heading"></a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="TALENT.model.models.node.NODE">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">TALENT.model.models.node.</span></span><span class="sig-name descname"><span class="pre">NODE</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">d_in</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_layers</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">layer_dim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">depth</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">tree_dim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">choice_function</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">bin_function</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">d_out</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a></span></em><span class="sig-paren">)</span><a class="headerlink" href="#TALENT.model.models.node.NODE" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="py method">
<dt class="sig sig-object py" id="TALENT.model.models.node.NODE.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x_num</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x_cat</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="headerlink" href="#TALENT.model.models.node.NODE.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">TALENT.model.models.node.</span></span><span class="sig-name descname"><span class="pre">Node</span></span></dt>
<dd><p>Neural implementation of oblivious decision trees with differentiable splits.</p>
<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layer_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_layers</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tree_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">depth</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">choice_function</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bin_function</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Initialize NODE architecture.</p>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p><strong>input_dim</strong> (<em>int</em>) – Input feature dimension</p></li>
<li><p><strong>layer_dim</strong> (<em>int</em>) – Hidden layer dimension</p></li>
<li><p><strong>output_dim</strong> (<em>int</em>) – Output dimension</p></li>
<li><p><strong>num_layers</strong> (<em>int</em>) – Number of NODE layers</p></li>
<li><p><strong>tree_dim</strong> (<em>int</em>) – Number of trees per layer</p></li>
<li><p><strong>depth</strong> (<em>int</em>) – Tree depth</p></li>
<li><p><strong>choice_function</strong> (<em>str</em>) – Function for feature selection (‘entmax15’)</p></li>
<li><p><strong>bin_function</strong> (<em>str</em>) – Function for threshold selection (‘entmoid15’)</p></li>
</ul>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Forward pass through oblivious decision trees.</p>
<p><strong>Decision Tree Mathematical Process:</strong></p>
<ol class="arabic simple">
<li><p><strong>Feature Selection:</strong> Use entmax for sparse feature selection</p></li>
<li><p><strong>Threshold Comparison:</strong> Compare features with learned thresholds</p></li>
<li><p><strong>Path Aggregation:</strong> Aggregate predictions along tree paths</p></li>
<li><p><strong>Ensemble Combination:</strong> Combine outputs from multiple trees</p></li>
</ol>
</dd></dl>

</dd></dl>

</section>
<section id="module-TALENT.model.models.grownet">
<span id="grownet-gradient-boosting-with-neural-networks"></span><h3>GrowNet (Gradient Boosting with Neural Networks)<a class="headerlink" href="#module-TALENT.model.models.grownet" title="Permalink to this heading"></a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="TALENT.model.models.grownet.DynamicNet">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">TALENT.model.models.grownet.</span></span><span class="sig-name descname"><span class="pre">DynamicNet</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">lr</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">categories</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.13)"><span class="pre">Optional</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.13)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">d_embedding</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.13)"><span class="pre">Optional</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#TALENT.model.models.grownet.DynamicNet" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></a></p>
<dl class="py method">
<dt class="sig sig-object py" id="TALENT.model.models.grownet.DynamicNet.add">
<span class="sig-name descname"><span class="pre">add</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#TALENT.model.models.grownet.DynamicNet.add" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="TALENT.model.models.grownet.DynamicNet.embed_input">
<span class="sig-name descname"><span class="pre">embed_input</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x_num</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x_cat</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#TALENT.model.models.grownet.DynamicNet.embed_input" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="TALENT.model.models.grownet.DynamicNet.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x_num</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x_cat</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#TALENT.model.models.grownet.DynamicNet.forward" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="TALENT.model.models.grownet.DynamicNet.forward_grad">
<span class="sig-name descname"><span class="pre">forward_grad</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x_num</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x_cat</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#TALENT.model.models.grownet.DynamicNet.forward_grad" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="TALENT.model.models.grownet.DynamicNet.from_file">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">from_file</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">builder</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#TALENT.model.models.grownet.DynamicNet.from_file" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="TALENT.model.models.grownet.DynamicNet.parameters">
<span class="sig-name descname"><span class="pre">parameters</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#TALENT.model.models.grownet.DynamicNet.parameters" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="TALENT.model.models.grownet.DynamicNet.to_cuda">
<span class="sig-name descname"><span class="pre">to_cuda</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#TALENT.model.models.grownet.DynamicNet.to_cuda" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="TALENT.model.models.grownet.DynamicNet.to_double">
<span class="sig-name descname"><span class="pre">to_double</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#TALENT.model.models.grownet.DynamicNet.to_double" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="TALENT.model.models.grownet.DynamicNet.to_eval">
<span class="sig-name descname"><span class="pre">to_eval</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#TALENT.model.models.grownet.DynamicNet.to_eval" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="TALENT.model.models.grownet.DynamicNet.to_file">
<span class="sig-name descname"><span class="pre">to_file</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">path</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#TALENT.model.models.grownet.DynamicNet.to_file" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="TALENT.model.models.grownet.DynamicNet.to_train">
<span class="sig-name descname"><span class="pre">to_train</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#TALENT.model.models.grownet.DynamicNet.to_train" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="TALENT.model.models.grownet.DynamicNet.zero_grad">
<span class="sig-name descname"><span class="pre">zero_grad</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#TALENT.model.models.grownet.DynamicNet.zero_grad" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="TALENT.model.models.grownet.ForwardType">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">TALENT.model.models.grownet.</span></span><span class="sig-name descname"><span class="pre">ForwardType</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">value</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">names</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">module</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">qualname</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">start</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">boundary</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#TALENT.model.models.grownet.ForwardType" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/enum.html#enum.Enum" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Enum</span></code></a></p>
<dl class="py attribute">
<dt class="sig sig-object py" id="TALENT.model.models.grownet.ForwardType.CASCADE">
<span class="sig-name descname"><span class="pre">CASCADE</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">2</span></em><a class="headerlink" href="#TALENT.model.models.grownet.ForwardType.CASCADE" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="TALENT.model.models.grownet.ForwardType.GRADIENT">
<span class="sig-name descname"><span class="pre">GRADIENT</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">3</span></em><a class="headerlink" href="#TALENT.model.models.grownet.ForwardType.GRADIENT" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="TALENT.model.models.grownet.ForwardType.SIMPLE">
<span class="sig-name descname"><span class="pre">SIMPLE</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">0</span></em><a class="headerlink" href="#TALENT.model.models.grownet.ForwardType.SIMPLE" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="TALENT.model.models.grownet.ForwardType.STACKED">
<span class="sig-name descname"><span class="pre">STACKED</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">1</span></em><a class="headerlink" href="#TALENT.model.models.grownet.ForwardType.STACKED" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="TALENT.model.models.grownet.MLP_2HL">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">TALENT.model.models.grownet.</span></span><span class="sig-name descname"><span class="pre">MLP_2HL</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dim_in</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dim_hidden1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dim_hidden2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dim_out</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sparse</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#TALENT.model.models.grownet.MLP_2HL" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="py method">
<dt class="sig sig-object py" id="TALENT.model.models.grownet.MLP_2HL.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lower_f</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#TALENT.model.models.grownet.MLP_2HL.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="TALENT.model.models.grownet.MLP_2HL.get_model">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">get_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">stage</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">opt</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#TALENT.model.models.grownet.MLP_2HL.get_model" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="TALENT.model.models.grownet.SpLinear">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">TALENT.model.models.grownet.</span></span><span class="sig-name descname"><span class="pre">SpLinear</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_features</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_features</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#TALENT.model.models.grownet.SpLinear" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="py method">
<dt class="sig sig-object py" id="TALENT.model.models.grownet.SpLinear.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#TALENT.model.models.grownet.SpLinear.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="TALENT.model.models.grownet.SpLinearFunc">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">TALENT.model.models.grownet.</span></span><span class="sig-name descname"><span class="pre">SpLinearFunc</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#TALENT.model.models.grownet.SpLinearFunc" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Function</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="TALENT.model.models.grownet.SpLinearFunc.backward">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">backward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ctx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">grad_output</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#TALENT.model.models.grownet.SpLinearFunc.backward" title="Permalink to this definition"></a></dt>
<dd><p>Defines a formula for differentiating the operation with backward mode
automatic differentiation (alias to the vjp function).</p>
<p>This function is to be overridden by all subclasses.</p>
<p>It must accept a context <code class="xref py py-attr docutils literal notranslate"><span class="pre">ctx</span></code> as the first argument, followed by
as many outputs as the <a class="reference internal" href="#TALENT.model.models.grownet.SpLinearFunc.forward" title="TALENT.model.models.grownet.SpLinearFunc.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a> returned (None will be passed in
for non tensor outputs of the forward function),
and it should return as many tensors, as there were inputs to
<a class="reference internal" href="#TALENT.model.models.grownet.SpLinearFunc.forward" title="TALENT.model.models.grownet.SpLinearFunc.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a>. Each argument is the gradient w.r.t the given output,
and each returned value should be the gradient w.r.t. the
corresponding input. If an input is not a Tensor or is a Tensor not
requiring grads, you can just pass None as a gradient for that input.</p>
<p>The context can be used to retrieve tensors saved during the forward
pass. It also has an attribute <code class="xref py py-attr docutils literal notranslate"><span class="pre">ctx.needs_input_grad</span></code> as a tuple
of booleans representing whether each input needs gradient. E.g.,
<a class="reference internal" href="#TALENT.model.models.grownet.SpLinearFunc.backward" title="TALENT.model.models.grownet.SpLinearFunc.backward"><code class="xref py py-func docutils literal notranslate"><span class="pre">backward()</span></code></a> will have <code class="docutils literal notranslate"><span class="pre">ctx.needs_input_grad[0]</span> <span class="pre">=</span> <span class="pre">True</span></code> if the
first input to <a class="reference internal" href="#TALENT.model.models.grownet.SpLinearFunc.forward" title="TALENT.model.models.grownet.SpLinearFunc.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a> needs gradient computated w.r.t. the
output.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="TALENT.model.models.grownet.SpLinearFunc.forward">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ctx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#TALENT.model.models.grownet.SpLinearFunc.forward" title="Permalink to this definition"></a></dt>
<dd><p>This function is to be overridden by all subclasses. There are two ways
to define forward:</p>
<p>Usage 1 (Combined forward and ctx):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nd">@staticmethod</span>
<span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">ctx</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
    <span class="k">pass</span>
</pre></div>
</div>
<ul class="simple">
<li><p>It must accept a context ctx as the first argument, followed by any
number of arguments (tensors or other types).</p></li>
<li><p>See <span class="xref std std-ref">combining-forward-context</span> for more details</p></li>
</ul>
<p>Usage 2 (Separate forward and ctx):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nd">@staticmethod</span>
<span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
    <span class="k">pass</span>

<span class="nd">@staticmethod</span>
<span class="k">def</span> <span class="nf">setup_context</span><span class="p">(</span><span class="n">ctx</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="n">inputs</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="o">...</span><span class="p">],</span> <span class="n">output</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="k">pass</span>
</pre></div>
</div>
<ul class="simple">
<li><p>The forward no longer accepts a ctx argument.</p></li>
<li><p>Instead, you must also override the <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.autograd.Function.setup_context()</span></code>
staticmethod to handle setting up the <code class="docutils literal notranslate"><span class="pre">ctx</span></code> object.
<code class="docutils literal notranslate"><span class="pre">output</span></code> is the output of the forward, <code class="docutils literal notranslate"><span class="pre">inputs</span></code> are a Tuple of inputs
to the forward.</p></li>
<li><p>See <span class="xref std std-ref">extending-autograd</span> for more details</p></li>
</ul>
<p>The context can be used to store arbitrary data that can be then
retrieved during the backward pass. Tensors should not be stored
directly on <cite>ctx</cite> (though this is not currently enforced for
backward compatibility). Instead, tensors should be saved either with
<code class="xref py py-func docutils literal notranslate"><span class="pre">ctx.save_for_backward()</span></code> if they are intended to be used in
<code class="docutils literal notranslate"><span class="pre">backward</span></code> (equivalently, <code class="docutils literal notranslate"><span class="pre">vjp</span></code>) or <code class="xref py py-func docutils literal notranslate"><span class="pre">ctx.save_for_forward()</span></code>
if they are intended to be used for in <code class="docutils literal notranslate"><span class="pre">jvp</span></code>.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">TALENT.model.models.grownet.</span></span><span class="sig-name descname"><span class="pre">GrowNet</span></span></dt>
<dd><p>Gradient boosting framework with neural network weak learners.</p>
<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">boost_rate</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layers_per_net</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layer_dims</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Initialize GrowNet with neural weak learners.</p>
<p><strong>Gradient Boosting Process:</strong></p>
<ol class="arabic simple">
<li><p><strong>Weak Learner Training:</strong> Train neural networks on residuals</p></li>
<li><p><strong>Boosting Update:</strong> Add weak learners with adaptive weights</p></li>
<li><p><strong>Gradient Computation:</strong> Compute gradients for next weak learner</p></li>
</ol>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Forward pass through the boosted ensemble.</p>
<p><strong>Boosting Mathematical Formulation:</strong></p>
<div class="math notranslate nohighlight">
\[F_m(x) = F_{m-1}(x) + \gamma_m h_m(x)\]</div>
<p>where <span class="math notranslate nohighlight">\(h_m\)</span> is the m-th weak learner and <span class="math notranslate nohighlight">\(\gamma_m\)</span> is the boosting rate.</p>
</dd></dl>

</dd></dl>

</section>
</section>
<section id="distance-based-models">
<h2>Distance-Based Models<a class="headerlink" href="#distance-based-models" title="Permalink to this heading"></a></h2>
<section id="modern-neighborhood-component-analysis-modernnca">
<h3>Modern Neighborhood Component Analysis (ModernNCA)<a class="headerlink" href="#modern-neighborhood-component-analysis-modernnca" title="Permalink to this heading"></a></h3>
<span class="target" id="module-TALENT.model.models.modernNCA"></span><dl class="py class">
<dt class="sig sig-object py" id="TALENT.model.models.modernNCA.MLP_Block">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">TALENT.model.models.modernNCA.</span></span><span class="sig-name descname"><span class="pre">MLP_Block</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.13)"><span class="pre">Any</span></a></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.13)"><span class="pre">Any</span></a></span></em><span class="sig-paren">)</span><a class="headerlink" href="#TALENT.model.models.modernNCA.MLP_Block" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="TALENT.model.models.modernNCA.MLP_Block.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#TALENT.model.models.modernNCA.MLP_Block.forward" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="TALENT.model.models.modernNCA.ModernNCA">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">TALENT.model.models.modernNCA.</span></span><span class="sig-name descname"><span class="pre">ModernNCA</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.13)"><span class="pre">Any</span></a></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.13)"><span class="pre">Any</span></a></span></em><span class="sig-paren">)</span><a class="headerlink" href="#TALENT.model.models.modernNCA.ModernNCA" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="TALENT.model.models.modernNCA.ModernNCA.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">candidate_x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">candidate_y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">is_train</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#TALENT.model.models.modernNCA.ModernNCA.forward" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="TALENT.model.models.modernNCA.ModernNCA.make_layer">
<span class="sig-name descname"><span class="pre">make_layer</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#TALENT.model.models.modernNCA.ModernNCA.make_layer" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">TALENT.model.models.modernNCA.</span></span><span class="sig-name descname"><span class="pre">ModernNCA</span></span></dt>
<dd><p>Neighborhood Component Analysis-inspired model for embedding-based predictions.</p>
<p><strong>Mathematical Formulation:</strong></p>
<p>ModernNCA learns embeddings for distance-based classification.</p>
<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">d_in</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">d_out</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">k</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">d_embedding</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Initialize ModernNCA model.</p>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p><strong>d_in</strong> (<em>int</em>) – Input feature dimension</p></li>
<li><p><strong>d_out</strong> (<em>int</em>) – Output dimension (number of classes)</p></li>
<li><p><strong>k</strong> (<em>int</em>) – Number of nearest neighbors to consider</p></li>
<li><p><strong>dropout</strong> (<em>float</em>) – Dropout probability</p></li>
<li><p><strong>d_embedding</strong> (<em>int</em>) – Embedding dimension</p></li>
</ul>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">candidate_x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">candidate_y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">is_train</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Forward pass with neighborhood analysis.</p>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p><strong>x</strong> (<em>torch.Tensor</em>) – Query features</p></li>
<li><p><strong>y</strong> (<em>torch.Tensor</em>) – Query labels</p></li>
<li><p><strong>candidate_x</strong> (<em>torch.Tensor</em>) – Candidate features for nearest neighbor search</p></li>
<li><p><strong>candidate_y</strong> (<em>torch.Tensor</em>) – Candidate labels</p></li>
<li><p><strong>is_train</strong> (<em>bool</em>) – Training mode flag</p></li>
</ul>
<p><strong>Returns:</strong></p>
<ul class="simple">
<li><p><strong>torch.Tensor</strong> – Distance-based predictions</p></li>
</ul>
<p><strong>Distance-Based Prediction Mathematical Implementation:</strong></p>
<ol class="arabic">
<li><p><strong>Embedding Computation:</strong></p>
<div class="math notranslate nohighlight">
\[e_i = f(x_i), \quad e_j = f(x_j)\]</div>
<p>where <span class="math notranslate nohighlight">\(f\)</span> is the learned embedding function.</p>
</li>
<li><p><strong>Distance Computation:</strong></p>
<div class="math notranslate nohighlight">
\[d(x_i, x_j) = ||e_i - e_j||_2\]</div>
</li>
<li><p><strong>Neighbor Weighting:</strong></p>
<div class="math notranslate nohighlight">
\[p_{ij} = \frac{\exp(-d(x_i, x_j))}{\sum_{k \neq i} \exp(-d(x_i, x_k))}\]</div>
</li>
<li><p><strong>Final Prediction:</strong></p>
<div class="math notranslate nohighlight">
\[\hat{y}_i = \sum_j p_{ij} y_j\]</div>
</li>
</ol>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">knn_prediction</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">candidate_x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">candidate_y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">k</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Make predictions using k-nearest neighbors in embedding space.</p>
<p><strong>K-NN Process:</strong></p>
<ol class="arabic simple">
<li><p><strong>Distance Calculation:</strong> Compute distances in embedding space</p></li>
<li><p><strong>Neighbor Selection:</strong> Find k nearest neighbors</p></li>
<li><p><strong>Prediction Aggregation:</strong> Aggregate neighbor labels with distance weighting</p></li>
</ol>
</dd></dl>

</dd></dl>

</section>
</section>
<section id="specialized-architectures">
<h2>Specialized Architectures<a class="headerlink" href="#specialized-architectures" title="Permalink to this heading"></a></h2>
<section id="module-TALENT.model.models.excelformer">
<span id="excelformer-semi-permeable-attention"></span><h3>ExcelFormer (Semi-Permeable Attention)<a class="headerlink" href="#module-TALENT.model.models.excelformer" title="Permalink to this heading"></a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="TALENT.model.models.excelformer.ExcelFormer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">TALENT.model.models.excelformer.</span></span><span class="sig-name descname"><span class="pre">ExcelFormer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">d_numerical</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">token_bias</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><span class="pre">bool</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_layers</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">d_token</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_heads</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">attention_dropout</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><span class="pre">float</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">ffn_dropout</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><span class="pre">float</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">residual_dropout</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><span class="pre">float</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">prenormalization</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><span class="pre">bool</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">kv_compression</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.13)"><span class="pre">Optional</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><span class="pre">float</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kv_compression_sharing</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.13)"><span class="pre">Optional</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">d_out</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">init_scale</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><span class="pre">float</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.1</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#TALENT.model.models.excelformer.ExcelFormer" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>ExcelFormer with All initialized by small value</p>
<p>initial function: v4</p>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="py method">
<dt class="sig sig-object py" id="TALENT.model.models.excelformer.ExcelFormer.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x_num</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x_cat</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mix_up</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><span class="pre">bool</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">beta</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'feat_mix'</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="headerlink" href="#TALENT.model.models.excelformer.ExcelFormer.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="TALENT.model.models.excelformer.MultiheadAttention">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">TALENT.model.models.excelformer.</span></span><span class="sig-name descname"><span class="pre">MultiheadAttention</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">d</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_heads</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><span class="pre">float</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">init_scale</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><span class="pre">float</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.01</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#TALENT.model.models.excelformer.MultiheadAttention" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="py method">
<dt class="sig sig-object py" id="TALENT.model.models.excelformer.MultiheadAttention.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x_q</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x_kv</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">key_compression</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.13)"><span class="pre">Optional</span></a><span class="p"><span class="pre">[</span></span><span class="pre">Linear</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">value_compression</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.13)"><span class="pre">Optional</span></a><span class="p"><span class="pre">[</span></span><span class="pre">Linear</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="headerlink" href="#TALENT.model.models.excelformer.MultiheadAttention.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="TALENT.model.models.excelformer.MultiheadAttention.get_attention_mask">
<span class="sig-name descname"><span class="pre">get_attention_mask</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#TALENT.model.models.excelformer.MultiheadAttention.get_attention_mask" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="TALENT.model.models.excelformer.Tokenizer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">TALENT.model.models.excelformer.</span></span><span class="sig-name descname"><span class="pre">Tokenizer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">d_numerical</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">categories</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.13)"><span class="pre">Optional</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.13)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">d_token</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">bias</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><span class="pre">bool</span></a></span></em><span class="sig-paren">)</span><a class="headerlink" href="#TALENT.model.models.excelformer.Tokenizer" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="TALENT.model.models.excelformer.Tokenizer.category_offsets">
<span class="sig-name descname"><span class="pre">category_offsets</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.13)"><span class="pre">Optional</span></a><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#TALENT.model.models.excelformer.Tokenizer.category_offsets" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="TALENT.model.models.excelformer.Tokenizer.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x_num</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="headerlink" href="#TALENT.model.models.excelformer.Tokenizer.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="TALENT.model.models.excelformer.Tokenizer.n_tokens">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">n_tokens</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a></em><a class="headerlink" href="#TALENT.model.models.excelformer.Tokenizer.n_tokens" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="TALENT.model.models.excelformer.attenuated_kaiming_uniform_">
<span class="sig-prename descclassname"><span class="pre">TALENT.model.models.excelformer.</span></span><span class="sig-name descname"><span class="pre">attenuated_kaiming_uniform_</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">a</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2.23606797749979</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'fan_in'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nonlinearity</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'leaky_relu'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#TALENT.model.models.excelformer.attenuated_kaiming_uniform_" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py class">
<dt class="sig sig-object py">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">TALENT.model.models.excelformer.</span></span><span class="sig-name descname"><span class="pre">ExcelFormer</span></span></dt>
<dd><p>Transformer with semi-permeable attention and mixup training capabilities.</p>
<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">d_numerical</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">d_token</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_blocks</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">attention_dropout</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ffn_dropout</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">residual_dropout</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">d_out</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Initialize ExcelFormer architecture.</p>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p><strong>d_numerical</strong> (<em>int</em>) – Number of numerical features</p></li>
<li><p><strong>d_token</strong> (<em>int</em>) – Token embedding dimension</p></li>
<li><p><strong>n_blocks</strong> (<em>int</em>) – Number of transformer blocks</p></li>
<li><p><strong>attention_dropout</strong> (<em>float</em>) – Attention dropout probability</p></li>
<li><p><strong>ffn_dropout</strong> (<em>float</em>) – Feed-forward dropout probability</p></li>
<li><p><strong>residual_dropout</strong> (<em>float</em>) – Residual connection dropout</p></li>
<li><p><strong>d_out</strong> (<em>int</em>) – Output dimension</p></li>
</ul>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x_num</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x_cat</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mix_up</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">beta</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mtype</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Forward pass with optional mixup augmentation.</p>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p><strong>x_num</strong> (<em>torch.Tensor</em>) – Numerical features</p></li>
<li><p><strong>x_cat</strong> (<em>torch.Tensor, optional</em>) – Categorical features</p></li>
<li><p><strong>mix_up</strong> (<em>bool</em>) – Whether to apply mixup</p></li>
<li><p><strong>beta</strong> (<em>float</em>) – Mixup parameter (default: 0.5)</p></li>
<li><p><strong>mtype</strong> (<em>str</em>) – Mixup type (‘feat_mix’, ‘hidden_mix’, ‘naive_mix’)</p></li>
</ul>
<p><strong>Returns:</strong></p>
<ul class="simple">
<li><p><strong>tuple</strong> – (output, feat_masks, shuffled_ids) for mixup training</p></li>
</ul>
<p><strong>Mixup Mathematical Implementation:</strong></p>
<p><strong>Feature Mixup:</strong></p>
<div class="math notranslate nohighlight">
\[\tilde{x} = \lambda x_i + (1-\lambda) x_j\]</div>
<p><strong>Semi-Permeable Attention:</strong></p>
<div class="math notranslate nohighlight">
\[\text{Attention}_{\text{perm}}(Q, K, V) = \text{mask} \odot \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V\]</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">mixup_process</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">beta</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mtype</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Apply mixup augmentation to input features.</p>
<p><strong>Mixup Types:</strong></p>
<ul class="simple">
<li><p><strong>feat_mix:</strong> Feature-level mixing with learnable weights</p></li>
<li><p><strong>hidden_mix:</strong> Hidden representation mixing</p></li>
<li><p><strong>naive_mix:</strong> Simple linear interpolation</p></li>
</ul>
</dd></dl>

</dd></dl>

</section>
<section id="module-TALENT.model.models.protogate">
<span id="protogate-prototype-based-gating"></span><h3>ProtoGate (Prototype-Based Gating)<a class="headerlink" href="#module-TALENT.model.models.protogate" title="Permalink to this heading"></a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="TALENT.model.models.protogate.DeactFunc">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">TALENT.model.models.protogate.</span></span><span class="sig-name descname"><span class="pre">DeactFunc</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.13)"><span class="pre">Any</span></a></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.13)"><span class="pre">Any</span></a></span></em><span class="sig-paren">)</span><a class="headerlink" href="#TALENT.model.models.protogate.DeactFunc" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="TALENT.model.models.protogate.DeactFunc.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#TALENT.model.models.protogate.DeactFunc.forward" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="TALENT.model.models.protogate.GatingNet">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">TALENT.model.models.protogate.</span></span><span class="sig-name descname"><span class="pre">GatingNet</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.13)"><span class="pre">Any</span></a></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.13)"><span class="pre">Any</span></a></span></em><span class="sig-paren">)</span><a class="headerlink" href="#TALENT.model.models.protogate.GatingNet" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Gating Network for feature selection</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_dim</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – input dimension of the gating network</p></li>
<li><p><strong>a</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a>) – coefficient in hard relu activation function</p></li>
<li><p><strong>sigma</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a>) – std of the gaussion reparameterization noise</p></li>
<li><p><strong>activation</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – activation function of the gating net: ‘relu’, ‘l_relu’, ‘sigmoid’, ‘tanh’, or ‘none’</p></li>
<li><p><strong>hidden_layer_list</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><em>list</em></a>) – number of nodes for each hidden layer of the gating net, example: [200,200]</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="TALENT.model.models.protogate.GatingNet.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#TALENT.model.models.protogate.GatingNet.forward" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="TALENT.model.models.protogate.GatingNet.get_stochastic_gate">
<span class="sig-name descname"><span class="pre">get_stochastic_gate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">alpha</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#TALENT.model.models.protogate.GatingNet.get_stochastic_gate" title="Permalink to this definition"></a></dt>
<dd><p>This function replaced the feature_selector function in order to save Z</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="TALENT.model.models.protogate.GatingNet.hard_sigmoid">
<span class="sig-name descname"><span class="pre">hard_sigmoid</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#TALENT.model.models.protogate.GatingNet.hard_sigmoid" title="Permalink to this definition"></a></dt>
<dd><p>Segment-wise linear approximation of sigmoid.
Faster than sigmoid.
Returns <cite>0.</cite> if <cite>x &lt; -2.5</cite>, <cite>1.</cite> if <cite>x &gt; 2.5</cite>.
In <cite>-2.5 &lt;= x &lt;= 2.5</cite>, returns <cite>0.2 * x + 0.5</cite>.
# Arguments</p>
<blockquote>
<div><p>x: A tensor or variable.</p>
</div></blockquote>
<dl class="simple">
<dt># Returns</dt><dd><p>A tensor.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="TALENT.model.models.protogate.HybridSort">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">TALENT.model.models.protogate.</span></span><span class="sig-name descname"><span class="pre">HybridSort</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.13)"><span class="pre">Any</span></a></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.13)"><span class="pre">Any</span></a></span></em><span class="sig-paren">)</span><a class="headerlink" href="#TALENT.model.models.protogate.HybridSort" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="TALENT.model.models.protogate.HybridSort.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">scores</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#TALENT.model.models.protogate.HybridSort.forward" title="Permalink to this definition"></a></dt>
<dd><p>scores: elements to be sorted. Typical shape: batch_size x n x 1</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="TALENT.model.models.protogate.KNNNet">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">TALENT.model.models.protogate.</span></span><span class="sig-name descname"><span class="pre">KNNNet</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.13)"><span class="pre">Any</span></a></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.13)"><span class="pre">Any</span></a></span></em><span class="sig-paren">)</span><a class="headerlink" href="#TALENT.model.models.protogate.KNNNet" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="TALENT.model.models.protogate.KNNNet.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">query</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">neighbors</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tau</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#TALENT.model.models.protogate.KNNNet.forward" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="TALENT.model.models.protogate.PL">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">TALENT.model.models.protogate.</span></span><span class="sig-name descname"><span class="pre">PL</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.13)"><span class="pre">Any</span></a></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.13)"><span class="pre">Any</span></a></span></em><span class="sig-paren">)</span><a class="headerlink" href="#TALENT.model.models.protogate.PL" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Distribution</span></code></p>
<p>scores. Shape: (batch_size x) n
tau: temperature for the relaxation. Scalar.
hard: use straight-through estimation if True</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="TALENT.model.models.protogate.PL.arg_constraints">
<span class="sig-name descname"><span class="pre">arg_constraints</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">{'scores':</span> <span class="pre">torch.distributions.constraints.positive,</span> <span class="pre">'tau':</span> <span class="pre">torch.distributions.constraints.positive}</span></em><a class="headerlink" href="#TALENT.model.models.protogate.PL.arg_constraints" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="TALENT.model.models.protogate.PL.has_rsample">
<span class="sig-name descname"><span class="pre">has_rsample</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">True</span></em><a class="headerlink" href="#TALENT.model.models.protogate.PL.has_rsample" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="TALENT.model.models.protogate.PL.log_prob">
<span class="sig-name descname"><span class="pre">log_prob</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">value</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#TALENT.model.models.protogate.PL.log_prob" title="Permalink to this definition"></a></dt>
<dd><p>value: permutation matrix. shape: batch_size x n x n</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="TALENT.model.models.protogate.PL.mean">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">mean</span></span><a class="headerlink" href="#TALENT.model.models.protogate.PL.mean" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="TALENT.model.models.protogate.PL.relaxed_sort">
<span class="sig-name descname"><span class="pre">relaxed_sort</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inp</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#TALENT.model.models.protogate.PL.relaxed_sort" title="Permalink to this definition"></a></dt>
<dd><p>inp: elements to be sorted. Typical shape: batch_size x n x 1</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="TALENT.model.models.protogate.PL.rsample">
<span class="sig-name descname"><span class="pre">rsample</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sample_shape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_score</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#TALENT.model.models.protogate.PL.rsample" title="Permalink to this definition"></a></dt>
<dd><p>sample_shape: number of samples from the PL distribution. Scalar.</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="TALENT.model.models.protogate.get_activation">
<span class="sig-prename descclassname"><span class="pre">TALENT.model.models.protogate.</span></span><span class="sig-name descname"><span class="pre">get_activation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">value</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#TALENT.model.models.protogate.get_activation" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py class">
<dt class="sig sig-object py">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">TALENT.model.models.protogate.</span></span><span class="sig-name descname"><span class="pre">ProtoGate</span></span></dt>
<dd><p>Prototype-based model with gating mechanisms for interpretable feature selection.</p>
<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_prototypes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_components</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Initialize ProtoGate architecture.</p>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p><strong>input_dim</strong> (<em>int</em>) – Input feature dimension</p></li>
<li><p><strong>output_dim</strong> (<em>int</em>) – Output dimension</p></li>
<li><p><strong>n_prototypes</strong> (<em>int</em>) – Number of learned prototypes</p></li>
<li><p><strong>n_components</strong> (<em>int</em>) – Number of components per prototype</p></li>
<li><p><strong>dropout</strong> (<em>float</em>) – Dropout probability</p></li>
</ul>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Forward pass with prototype-based gating.</p>
<p><strong>Prototype-Based Processing:</strong></p>
<ol class="arabic simple">
<li><p><strong>Prototype Computation:</strong> Learn representative prototypes from data</p></li>
<li><p><strong>Distance Calculation:</strong> Compute distances to prototypes</p></li>
<li><p><strong>Gate Generation:</strong> Use distances to generate feature gates</p></li>
<li><p><strong>Feature Selection:</strong> Apply gates for adaptive feature selection</p></li>
</ol>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">TALENT.model.models.protogate.</span></span><span class="sig-name descname"><span class="pre">GatingNet</span></span></dt>
<dd><p>Gating network for prototype-based feature selection.</p>
<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">hard_sigmoid</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Hard sigmoid activation for efficient gating.</p>
<p><strong>Hard Sigmoid Mathematical Definition:</strong></p>
<div class="math notranslate nohighlight">
\[\text{hard_sigmoid}(x) = \max(0, \min(1, \frac{x + 1}{2}))\]</div>
<p>This provides a piecewise linear approximation to the sigmoid function for computational efficiency.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Generate gating weights for feature selection.</p>
</dd></dl>

</dd></dl>

</section>
</section>
<section id="retrieval-based-models">
<h2>Retrieval-Based Models<a class="headerlink" href="#retrieval-based-models" title="Permalink to this heading"></a></h2>
<section id="module-TALENT.model.models.tabr">
<span id="tabr-tabular-retrieval"></span><h3>TabR (Tabular Retrieval)<a class="headerlink" href="#module-TALENT.model.models.tabr" title="Permalink to this heading"></a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="TALENT.model.models.tabr.TabR">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">TALENT.model.models.tabr.</span></span><span class="sig-name descname"><span class="pre">TabR</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.13)"><span class="pre">Any</span></a></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.13)"><span class="pre">Any</span></a></span></em><span class="sig-paren">)</span><a class="headerlink" href="#TALENT.model.models.tabr.TabR" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="TALENT.model.models.tabr.TabR.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x_num</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x_cat</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.13)"><span class="pre">Optional</span></a><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.13)"><span class="pre">Optional</span></a><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">candidate_x_num</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.13)"><span class="pre">Optional</span></a><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">candidate_x_cat</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.13)"><span class="pre">Optional</span></a><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">candidate_y</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">context_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">is_train</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><span class="pre">bool</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#TALENT.model.models.tabr.TabR.forward" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="TALENT.model.models.tabr.TabR.reset_parameters">
<span class="sig-name descname"><span class="pre">reset_parameters</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#TALENT.model.models.tabr.TabR.reset_parameters" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">TALENT.model.models.tabr.</span></span><span class="sig-name descname"><span class="pre">TabR</span></span></dt>
<dd><p>KNN-attention hybrid model with retrieval-based predictions.</p>
<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">__init__(n_num_features,</span> <span class="pre">n_cat_features,</span> <span class="pre">n_classes,</span> <span class="pre">context_size,</span> <span class="pre">normalization,</span> <span class="pre">num_embeddings,</span> <span class="pre">d_main,</span> <span class="pre">d_multiplier,</span> <span class="pre">encoder_n_blocks,</span> <span class="pre">predictor_n_blocks,</span> <span class="pre">mixer_normalization,</span> <span class="pre">dropout0,</span> <span class="pre">dropout1,</span> <span class="pre">normalization,</span> <span class="pre">activation)</span></span></dt>
<dd><p>Initialize TabR architecture.</p>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p><strong>n_num_features</strong> (<em>int</em>) – Number of numerical features</p></li>
<li><p><strong>n_cat_features</strong> (<em>int</em>) – Number of categorical features</p></li>
<li><p><strong>n_classes</strong> (<em>int</em>) – Number of output classes</p></li>
<li><p><strong>context_size</strong> (<em>int</em>) – Maximum context size for retrieval</p></li>
<li><p><strong>normalization</strong> (<em>str</em>) – Normalization type</p></li>
<li><p><strong>num_embeddings</strong> (<em>dict</em>) – Embedding configurations</p></li>
<li><p><strong>d_main</strong> (<em>int</em>) – Main hidden dimension</p></li>
<li><p><strong>d_multiplier</strong> (<em>int</em>) – Dimension multiplier</p></li>
<li><p><strong>encoder_n_blocks</strong> (<em>int</em>) – Number of encoder blocks</p></li>
<li><p><strong>predictor_n_blocks</strong> (<em>int</em>) – Number of predictor blocks</p></li>
<li><p><strong>mixer_normalization</strong> (<em>str</em>) – Mixer normalization type</p></li>
<li><p><strong>dropout0</strong> (<em>float</em>) – Input dropout</p></li>
<li><p><strong>dropout1</strong> (<em>float</em>) – Hidden dropout</p></li>
<li><p><strong>activation</strong> (<em>str</em>) – Activation function</p></li>
</ul>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x_num</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x_cat</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">candidate_x_num</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">candidate_x_cat</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">candidate_y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">context_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">is_train</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Forward pass with retrieval-based attention.</p>
<p><strong>Retrieval Process:</strong></p>
<ol class="arabic simple">
<li><p><strong>Context Selection:</strong> Select relevant examples from training set</p></li>
<li><p><strong>Attention Computation:</strong> Apply attention over retrieved candidates</p></li>
<li><p><strong>Feature Processing:</strong> Process query and candidate features</p></li>
<li><p><strong>Prediction Generation:</strong> Combine retrieval and learned representations</p></li>
</ol>
</dd></dl>

</dd></dl>

</section>
</section>
<section id="foundation-models">
<h2>Foundation Models<a class="headerlink" href="#foundation-models" title="Permalink to this heading"></a></h2>
<section id="module-TALENT.model.models.tabpfn">
<span id="tabpfn-tabular-prior-fitting-networks"></span><h3>TabPFN (Tabular Prior-Fitting Networks)<a class="headerlink" href="#module-TALENT.model.models.tabpfn" title="Permalink to this heading"></a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="TALENT.model.models.tabpfn.TabPFNClassifier">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">TALENT.model.models.tabpfn.</span></span><span class="sig-name descname"><span class="pre">TabPFNClassifier</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.13)"><span class="pre">Any</span></a></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.13)"><span class="pre">Any</span></a></span></em><span class="sig-paren">)</span><a class="headerlink" href="#TALENT.model.models.tabpfn.TabPFNClassifier" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">BaseEstimator</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">ClassifierMixin</span></code></p>
<p>Initializes the classifier and loads the model.
Depending on the arguments, the model is either loaded from memory, from a file, or downloaded from the
repository if no model is found.</p>
<p>Can also be used to compute gradients with respect to the inputs X_train and X_test. Therefore no_grad has to be
set to False and no_preprocessing_mode must be True. Furthermore, X_train and X_test need to be given as
torch.Tensors and their requires_grad parameter must be set to True.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>device</strong> – If the model should run on cuda or cpu.</p></li>
<li><p><strong>base_path</strong> – Base path of the directory, from which the folders like models_diff can be accessed.</p></li>
<li><p><strong>model_string</strong> – Name of the model. Used first to check if the model is already in memory, and if not,
tries to load a model with that name from the models_diff directory. It looks for files named as
follows: “prior_diff_real_checkpoint” + model_string + “_n_0_epoch_e.cpkt”, where e can be a number
between 100 and 0, and is checked in a descending order.</p></li>
<li><p><strong>N_ensemble_configurations</strong> – The number of ensemble configurations used for the prediction. Thereby the
accuracy, but also the running time, increases with this number.</p></li>
<li><p><strong>no_preprocess_mode</strong> – Specifies whether preprocessing is to be performed.</p></li>
<li><p><strong>multiclass_decoder</strong> – If set to permutation, randomly shifts the classes for each ensemble configuration.</p></li>
<li><p><strong>feature_shift_decoder</strong> – If set to true shifts the features for each ensemble configuration according to a
random permutation.</p></li>
<li><p><strong>only_inference</strong> – Indicates if the model should be loaded to only restore inference capabilities or also
training capabilities. Note that the training capabilities are currently not being fully restored.</p></li>
<li><p><strong>seed</strong> – Seed that is used for the prediction. Allows for a deterministic behavior of the predictions.</p></li>
<li><p><strong>batch_size_inference</strong> – This parameter is a trade-off between performance and memory consumption.
The computation done with different values for batch_size_inference is the same,
but it is split into smaller/larger batches.</p></li>
<li><p><strong>no_grad</strong> – If set to false, allows for the computation of gradients with respect to X_train and X_test.
For this to correctly function no_preprocessing_mode must be set to true.</p></li>
<li><p><strong>subsample_features</strong> – If set to true and the number of features in the dataset exceeds self.max_features (100),
the features are subsampled to self.max_features.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="TALENT.model.models.tabpfn.TabPFNClassifier.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">overwrite_warning</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#TALENT.model.models.tabpfn.TabPFNClassifier.fit" title="Permalink to this definition"></a></dt>
<dd><p>Validates the training set and stores it.</p>
<p>If clf.no_grad (default is True):
X, y should be of type np.array
else:
X should be of type torch.Tensors (y can be np.array or torch.Tensor)</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="TALENT.model.models.tabpfn.TabPFNClassifier.load_result_minimal">
<span class="sig-name descname"><span class="pre">load_result_minimal</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">i</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">e</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#TALENT.model.models.tabpfn.TabPFNClassifier.load_result_minimal" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="TALENT.model.models.tabpfn.TabPFNClassifier.models_in_memory">
<span class="sig-name descname"><span class="pre">models_in_memory</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">{}</span></em><a class="headerlink" href="#TALENT.model.models.tabpfn.TabPFNClassifier.models_in_memory" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="TALENT.model.models.tabpfn.TabPFNClassifier.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_winning_probability</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">normalize_with_test</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#TALENT.model.models.tabpfn.TabPFNClassifier.predict" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="TALENT.model.models.tabpfn.TabPFNClassifier.predict_proba">
<span class="sig-name descname"><span class="pre">predict_proba</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">normalize_with_test</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_logits</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#TALENT.model.models.tabpfn.TabPFNClassifier.predict_proba" title="Permalink to this definition"></a></dt>
<dd><p>Predict the probabilities for the input X depending on the training set previously passed in the method fit.</p>
<p>If no_grad is true in the classifier the function takes X as a numpy.ndarray. If no_grad is false X must be a
torch tensor and is not fully checked.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="TALENT.model.models.tabpfn.TabPFNClassifier.remove_models_from_memory">
<span class="sig-name descname"><span class="pre">remove_models_from_memory</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#TALENT.model.models.tabpfn.TabPFNClassifier.remove_models_from_memory" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">TALENT.model.models.tabpfn.</span></span><span class="sig-name descname"><span class="pre">TabPFNClassifier</span></span></dt>
<dd><p>Prior-fitting network for zero-shot tabular classification.</p>
<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">device</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_path</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Initialize TabPFN with pre-trained weights.</p>
<p><strong>Foundation Model Features:</strong></p>
<ul class="simple">
<li><p>Pre-trained on diverse tabular datasets</p></li>
<li><p>No gradient-based training required</p></li>
<li><p>Immediate deployment capability</p></li>
<li><p>Context-based learning from examples</p></li>
</ul>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Fit the model using in-context learning (no parameter updates).</p>
<p><strong>In-Context Learning Process:</strong></p>
<ol class="arabic simple">
<li><p><strong>Context Setup:</strong> Store training examples as context</p></li>
<li><p><strong>No Weight Updates:</strong> Model weights remain frozen</p></li>
<li><p><strong>Context Encoding:</strong> Encode training data for reference</p></li>
</ol>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">predict_proba</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Make predictions using in-context learning.</p>
<p><strong>Zero-Shot Prediction:</strong></p>
<ol class="arabic simple">
<li><p><strong>Context Retrieval:</strong> Use stored training context</p></li>
<li><p><strong>Attention Mechanism:</strong> Apply attention over training examples</p></li>
<li><p><strong>Prediction Generation:</strong> Generate predictions without fine-tuning</p></li>
</ol>
</dd></dl>

</dd></dl>

</section>
</section>
<section id="regularization-methods">
<h2>Regularization Methods<a class="headerlink" href="#regularization-methods" title="Permalink to this heading"></a></h2>
<section id="tangos-regularization">
<h3>TANGOS Regularization<a class="headerlink" href="#tangos-regularization" title="Permalink to this heading"></a></h3>
<span class="target" id="module-TALENT.model.models.tangos"></span><dl class="py class">
<dt class="sig sig-object py" id="TALENT.model.models.tangos.Tangos">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">TALENT.model.models.tangos.</span></span><span class="sig-name descname"><span class="pre">Tangos</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.13)"><span class="pre">Any</span></a></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.13)"><span class="pre">Any</span></a></span></em><span class="sig-paren">)</span><a class="headerlink" href="#TALENT.model.models.tangos.Tangos" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="TALENT.model.models.tangos.Tangos.cal_representation">
<span class="sig-name descname"><span class="pre">cal_representation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#TALENT.model.models.tangos.Tangos.cal_representation" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="TALENT.model.models.tangos.Tangos.cal_tangos_loss">
<span class="sig-name descname"><span class="pre">cal_tangos_loss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#TALENT.model.models.tangos.Tangos.cal_tangos_loss" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="TALENT.model.models.tangos.Tangos.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x_cat</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#TALENT.model.models.tangos.Tangos.forward" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">TALENT.model.models.tangos.</span></span><span class="sig-name descname"><span class="pre">Tangos</span></span></dt>
<dd><p>MLP with TANGOS regularization for neuron specialization.</p>
<p><strong>Mathematical Formulation:</strong></p>
<p>TANGOS applies spatial and spectral regularization to encourage neuron specialization:</p>
<div class="math notranslate nohighlight">
\[\mathcal{L}_{\text{TANGOS}} = \mathcal{L}_{\text{task}} + \lambda_1 \mathcal{L}_{\text{spatial}} + \lambda_2 \mathcal{L}_{\text{spectral}}\]</div>
<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">d_in</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">d_out</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">d_layers</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lambda1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lambda2</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Initialize TANGOS-regularized MLP.</p>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p><strong>d_in</strong> (<em>int</em>) – Input dimension</p></li>
<li><p><strong>d_out</strong> (<em>int</em>) – Output dimension</p></li>
<li><p><strong>d_layers</strong> (<em>List[int]</em>) – Hidden layer dimensions</p></li>
<li><p><strong>dropout</strong> (<em>float</em>) – Dropout probability</p></li>
<li><p><strong>lambda1</strong> (<em>float</em>) – Spatial regularization weight</p></li>
<li><p><strong>lambda2</strong> (<em>float</em>) – Spectral regularization weight</p></li>
</ul>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x_cat</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Forward pass with standard MLP architecture.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">cal_representation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Calculate intermediate representations for regularization.</p>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p><strong>x</strong> (<em>torch.Tensor</em>) – Input features</p></li>
</ul>
<p><strong>Returns:</strong></p>
<ul class="simple">
<li><p><strong>torch.Tensor</strong> – Hidden representations before final layer</p></li>
</ul>
<p><strong>Representation Extraction Process:</strong></p>
<p>The method extracts intermediate representations by stopping before the final layer:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">layer</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="ow">and</span> <span class="n">i</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">)</span>
<span class="k">return</span> <span class="n">x</span>  <span class="c1"># Return before final head layer</span>
</pre></div>
</div>
<p><strong>Regularization Applications:</strong></p>
<ul class="simple">
<li><p><strong>Spatial Regularization:</strong> Encourages spatial locality in neuron activations</p></li>
<li><p><strong>Spectral Regularization:</strong> Promotes spectral diversity in learned representations</p></li>
</ul>
</dd></dl>

</dd></dl>

</section>
</section>
<section id="activation-functions-reference">
<h2>Activation Functions Reference<a class="headerlink" href="#activation-functions-reference" title="Permalink to this heading"></a></h2>
<p><strong>Standard Activations:</strong></p>
<div class="math notranslate nohighlight">
\[\text{ReLU}(x) = \max(0, x)\]</div>
<div class="math notranslate nohighlight">
\[\text{GELU}(x) = x \cdot \Phi(x) = x \cdot \frac{1}{2}\left[1 + \text{erf}\left(\frac{x}{\sqrt{2}}\right)\right]\]</div>
<div class="math notranslate nohighlight">
\[\begin{split}\text{SELU}(x) = \lambda \begin{cases}
x &amp; \text{if } x &gt; 0 \\
\alpha(e^x - 1) &amp; \text{if } x \leq 0
\end{cases}\end{split}\]</div>
<p><strong>Gated Activations:</strong></p>
<div class="math notranslate nohighlight">
\[\text{ReGLU}(x) = a \cdot \text{ReLU}(b) \text{ where } [a, b] = \text{split}(x)\]</div>
<div class="math notranslate nohighlight">
\[\text{GeGLU}(x) = a \cdot \text{GELU}(b) \text{ where } [a, b] = \text{split}(x)\]</div>
<p><strong>Probability Functions:</strong></p>
<div class="math notranslate nohighlight">
\[\text{Softmax}(x_i) = \frac{\exp(x_i)}{\sum_{j=1}^K \exp(x_j)}\]</div>
<div class="math notranslate nohighlight">
\[\text{Sparsemax}(z) = \arg\min_{p \in \Delta^{K-1}} ||p - z||_2^2\]</div>
<p>where <span class="math notranslate nohighlight">\(\Delta^{K-1}\)</span> is the probability simplex.</p>
</section>
<section id="model-usage-examples">
<h2>Model Usage Examples<a class="headerlink" href="#model-usage-examples" title="Permalink to this heading"></a></h2>
<p><strong>Basic MLP Usage:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">TALENT.model.models.mlp</span> <span class="kn">import</span> <span class="n">MLP</span>

<span class="c1"># Initialize MLP</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">(</span>
    <span class="n">d_in</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>           <span class="c1"># Input dimension</span>
    <span class="n">d_out</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>           <span class="c1"># Output dimension (3 classes)</span>
    <span class="n">d_layers</span><span class="o">=</span><span class="p">[</span><span class="mi">64</span><span class="p">,</span> <span class="mi">32</span><span class="p">],</span> <span class="c1"># Hidden layer sizes</span>
    <span class="n">dropout</span><span class="o">=</span><span class="mf">0.1</span>        <span class="c1"># Dropout probability</span>
<span class="p">)</span>

<span class="c1"># Forward pass</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>  <span class="c1"># Batch of 32 samples, 10 features</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>        <span class="c1"># Shape: (32, 3)</span>
</pre></div>
</div>
<p><strong>ResNet with Advanced Activations:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">TALENT.model.models.resnet</span> <span class="kn">import</span> <span class="n">ResNet</span>

<span class="c1"># Initialize ResNet with GeGLU activation</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">ResNet</span><span class="p">(</span>
    <span class="n">d_in</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span>
    <span class="n">d_out</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>                    <span class="c1"># Regression task</span>
    <span class="n">d</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>                      <span class="c1"># Hidden dimension</span>
    <span class="n">d_hidden_factor</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span>        <span class="c1"># Hidden expansion factor</span>
    <span class="n">n_layers</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>                 <span class="c1"># Number of residual blocks</span>
    <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;geglu&#39;</span><span class="p">,</span>         <span class="c1"># GeGLU activation</span>
    <span class="n">normalization</span><span class="o">=</span><span class="s1">&#39;layernorm&#39;</span><span class="p">,</span>  <span class="c1"># Layer normalization</span>
    <span class="n">hidden_dropout</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
    <span class="n">residual_dropout</span><span class="o">=</span><span class="mf">0.1</span>
<span class="p">)</span>
</pre></div>
</div>
<p><strong>FT-Transformer with Mixed Features:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">TALENT.model.models.ftt</span> <span class="kn">import</span> <span class="n">Transformer</span>

<span class="c1"># Initialize FT-Transformer</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Transformer</span><span class="p">(</span>
    <span class="n">d_numerical</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>          <span class="c1"># 8 numerical features</span>
    <span class="n">categories</span><span class="o">=</span><span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>  <span class="c1"># 3 categorical features with cardinalities</span>
    <span class="n">d_token</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>             <span class="c1"># Token dimension</span>
    <span class="n">n_layers</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>             <span class="c1"># Number of transformer layers</span>
    <span class="n">n_heads</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>              <span class="c1"># Attention heads</span>
    <span class="n">d_ffn_factor</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span>       <span class="c1"># FFN expansion factor</span>
    <span class="n">attention_dropout</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
    <span class="n">ffn_dropout</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
    <span class="n">residual_dropout</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
    <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;reglu&#39;</span><span class="p">,</span>
    <span class="n">prenormalization</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">d_out</span><span class="o">=</span><span class="mi">5</span>                 <span class="c1"># 5 classes</span>
<span class="p">)</span>
</pre></div>
</div>
<p><strong>TabNet for Interpretable Classification:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">TALENT.model.models.tabnet</span> <span class="kn">import</span> <span class="n">TabNetClassifier</span>

<span class="c1"># Initialize TabNet</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">TabNetClassifier</span><span class="p">(</span>
    <span class="n">n_steps</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>              <span class="c1"># Decision steps</span>
    <span class="n">gamma</span><span class="o">=</span><span class="mf">1.3</span><span class="p">,</span>              <span class="c1"># Relaxation parameter</span>
    <span class="n">n_independent</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>        <span class="c1"># Independent GLU layers</span>
    <span class="n">n_shared</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>             <span class="c1"># Shared GLU layers</span>
    <span class="n">momentum</span><span class="o">=</span><span class="mf">0.02</span><span class="p">,</span>          <span class="c1"># Batch norm momentum</span>
    <span class="n">lambda_sparse</span><span class="o">=</span><span class="mf">1e-3</span>      <span class="c1"># Sparsity regularization</span>
<span class="p">)</span>

<span class="c1"># Training</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span>
          <span class="n">eval_set</span><span class="o">=</span><span class="p">[(</span><span class="n">X_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">)],</span>
          <span class="n">max_epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>

<span class="c1"># Get predictions and explanations</span>
<span class="n">predictions</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">explanations</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">explain</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>GRANDE for Tree-like Neural Networks:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">TALENT.model.models.grande</span> <span class="kn">import</span> <span class="n">GRANDE</span>

<span class="c1"># Initialize GRANDE</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">GRANDE</span><span class="p">(</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
    <span class="n">task_type</span><span class="o">=</span><span class="s1">&#39;classification&#39;</span><span class="p">,</span>
    <span class="n">depth</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>              <span class="c1"># Tree depth</span>
    <span class="n">n_estimators</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>      <span class="c1"># Number of trees</span>
    <span class="n">dropout</span><span class="o">=</span><span class="mf">0.1</span>
<span class="p">)</span>
</pre></div>
</div>
<p><strong>ModernNCA with Distance-Based Learning:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">TALENT.model.models.modernNCA</span> <span class="kn">import</span> <span class="n">ModernNCA</span>

<span class="c1"># Initialize ModernNCA</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">ModernNCA</span><span class="p">(</span>
    <span class="n">d_in</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span>
    <span class="n">d_out</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>              <span class="c1"># 4 classes</span>
    <span class="n">k</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>                 <span class="c1"># Number of neighbors</span>
    <span class="n">dropout</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
    <span class="n">d_embedding</span><span class="o">=</span><span class="mi">64</span>        <span class="c1"># Embedding dimension</span>
<span class="p">)</span>

<span class="c1"># Training requires candidate examples</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">candidate_x</span><span class="p">,</span> <span class="n">candidate_y</span><span class="p">,</span> <span class="n">is_train</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>ExcelFormer with Mixup Training:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">TALENT.model.models.excelformer</span> <span class="kn">import</span> <span class="n">ExcelFormer</span>

<span class="c1"># Initialize ExcelFormer</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">ExcelFormer</span><span class="p">(</span>
    <span class="n">d_numerical</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">d_token</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
    <span class="n">n_blocks</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
    <span class="n">attention_dropout</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
    <span class="n">ffn_dropout</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
    <span class="n">d_out</span><span class="o">=</span><span class="mi">3</span>
<span class="p">)</span>

<span class="c1"># Forward pass with feature mixup</span>
<span class="n">output</span><span class="p">,</span> <span class="n">masks</span><span class="p">,</span> <span class="n">shuffled_ids</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span>
    <span class="n">x_num</span><span class="p">,</span>
    <span class="n">mix_up</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">beta</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
    <span class="n">mtype</span><span class="o">=</span><span class="s1">&#39;feat_mix&#39;</span>
<span class="p">)</span>
</pre></div>
</div>
<p><strong>TabPFN for Zero-Shot Learning:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">TALENT.model.models.tabpfn</span> <span class="kn">import</span> <span class="n">TabPFNClassifier</span>

<span class="c1"># Initialize pre-trained TabPFN</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">TabPFNClassifier</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="s1">&#39;cuda&#39;</span><span class="p">)</span>

<span class="c1"># No training required - just fit context</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Immediate predictions</span>
<span class="n">predictions</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="model-selection-guidelines">
<h2>Model Selection Guidelines<a class="headerlink" href="#model-selection-guidelines" title="Permalink to this heading"></a></h2>
<p><strong>For Beginners:</strong>
- <strong>MLP:</strong> Simple, fast, good baseline
- <strong>ResNet:</strong> Better than MLP for deeper networks</p>
<p><strong>For Best Performance:</strong>
- <strong>FT-Transformer:</strong> State-of-the-art on many datasets
- <strong>TabNet:</strong> Excellent performance with interpretability
- <strong>ModernNCA:</strong> Strong embedding-based performance</p>
<p><strong>For Interpretability:</strong>
- <strong>TabNet:</strong> Attention-based feature importance
- <strong>GRANDE:</strong> Tree-like decision process
- <strong>ProtoGate:</strong> Prototype-based explanations</p>
<p><strong>For Speed:</strong>
- <strong>MLP:</strong> Fastest training and inference
- <strong>SNN:</strong> Lightweight with self-normalization
- <strong>TabPFN:</strong> No training required</p>
<p><strong>For Specific Scenarios:</strong>
- <strong>TabR:</strong> Retrieval-based learning
- <strong>ExcelFormer:</strong> Complex feature interactions with mixup
- <strong>TANGOS:</strong> When regularization is critical</p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="deep_learning.html" class="btn btn-neutral float-left" title="Deep Learning Models" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="methods.html" class="btn btn-neutral float-right" title="Methods" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2024, Read the Docs core team.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>